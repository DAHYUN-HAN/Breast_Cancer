{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import sys\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageMath\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from img_processing_256 import mask_img, rename\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotate_image_train(img):\n",
    "    rotations = np.random.randint(low=-3, high=3)\n",
    "    return np.rot90(img, rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_img_train(img):\n",
    "    fliplr = np.random.binomial(1,0.5)\n",
    "    flipud = np.random.binomial(1,0.5)\n",
    "    \n",
    "    if fliplr:\n",
    "        img = np.flip(img, 1)\n",
    "    if flipud:\n",
    "        img = np.flip(img, 0)\n",
    "        \n",
    "    return random_rotate_image_train(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    slice_size=512\n",
    "    tile_size=256\n",
    "    img_h = img.shape[0]\n",
    "    img_w = img.shape[1]\n",
    "    \n",
    "    # make sure the image is big enough to use\n",
    "    if (img_h < slice_size) or (img_w < slice_size):\n",
    "        print(\"Error - image is wrong size!\", img.shape)\n",
    "        return np.array([0])\n",
    "    \n",
    "    # pick a random place to start the crop so that the crop will be the right size\n",
    "    start_row = np.random.randint(low=0, high=(img_h - slice_size))\n",
    "    start_col = np.random.randint(low=0, high=(img_w - slice_size))\n",
    "    \n",
    "    end_row = start_row + slice_size\n",
    "    end_col = start_col + slice_size\n",
    "    \n",
    "    # crop the image and randomly rotate it\n",
    "    cropped_img = random_flip_img_train(img[start_row:end_row, start_col:end_col])\n",
    "    \n",
    "    # make sure the image is the right size\n",
    "    if cropped_img.shape[0] == cropped_img.shape[1]:\n",
    "        # resize it and return it\n",
    "        cropped_img = cropped_img.astype('float32')\n",
    "        cropped_img = cv2.resize(cropped_img, dsize=(tile_size, tile_size), interpolation=cv2.INTER_CUBIC) \n",
    "        return cropped_img.reshape((tile_size, tile_size, 1))\n",
    "    \n",
    "    # else repeat until the image is the right size\n",
    "    else:\n",
    "        return crop_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(mask_dir, img_dir, Lbls, size=256, debug=True):\n",
    "    patch_list = []\n",
    "    Lbl_list = []\n",
    "    FN_list = []\n",
    "    roi_sizes = []\n",
    "    full_size = 512\n",
    "    masks = os.listdir(mask_dir)\n",
    "    counter = 0\n",
    "    if debug is None:\n",
    "        progress(counter, len(masks), 'WORKING')\n",
    "    for mask in tqdm(masks):\n",
    "        counter += 1\n",
    "        if debug is None:\n",
    "            progress(counter, len(masks), mask)    \n",
    "            \n",
    "        base_img_file = mask[:-6] + \".png\"\n",
    "        full_img = PIL.Image.open(img_dir+\"/\"+base_img_file)\n",
    "        compare = base_img_file[14:]\n",
    "        \n",
    "        try:\n",
    "            Lbl = Lbls.loc[compare]['Class']\n",
    "        except:\n",
    "            print(\"Error LabelNotFound\", base_img_file)\n",
    "            continue\n",
    "        \n",
    "        full_img_arr = np.array(full_img)[:,:]\n",
    "        ctr_row, ctr_col, too_big, full_img_arr, mask_size = mask_img(mask_dir + \"/\" + mask,full_img_arr, half=False,\n",
    "                                                                         output=debug)\n",
    "        img_h, img_w = full_img_arr.shape\n",
    "        try:\n",
    "            mask_H = mask_size[0]\n",
    "            mask_W = mask_size[1]\n",
    "            roi_size = np.max([mask_H, mask_W])\n",
    "            if debug:\n",
    "                print(\"Mask\", mask, \" Height:\", mask_H, \"Width:\", mask_W)\n",
    "        except:\n",
    "            print(\"Mask Size Error:\", mask_size, \"for\", mask)\n",
    "        # Record roi size for DDSM image crop\n",
    "        roi_sizes.append(roi_size)\n",
    "        if (ctr_row == 0) and (ctr_col == 0):\n",
    "            print(\"Error, skipping\", mask)\n",
    "            continue\n",
    "        \"\"\"\n",
    "        Extract the ROI depending on it's size\n",
    "        If the ROI is smaller than a slice extract it with some padding\n",
    "        \"\"\"\n",
    "        if roi_size < full_size:\n",
    "            if debug:\n",
    "                print(\"ROI small\", mask)\n",
    "            ## Make sure the size of the ROI is at least as big as a tile will be\n",
    "            adj_mask_H = int(np.max([full_size * 1.4, mask_H]))\n",
    "            adj_mask_W = int(np.max([full_size * 1.4, mask_W]))\n",
    "            ## Extract the full ROI with 20% padding on either side\n",
    "            start_row = int(np.max([ctr_row - (adj_mask_H // 2), 0]))\n",
    "            end_row = start_row + adj_mask_H\n",
    "            if end_row > img_h:\n",
    "                end_row = img_h\n",
    "                start_row = img_h - adj_mask_H\n",
    "            start_col = int(np.max([ctr_col - (adj_mask_W // 2), 0]))\n",
    "            end_col = start_col + adj_mask_W\n",
    "            if end_col > img_w:\n",
    "                end_col = img_w\n",
    "                start_col = img_w - adj_mask_W\n",
    "\n",
    "            # extract the ROI and randomly flip it\n",
    "            roi_img = random_flip_img_train(full_img_arr[start_row:end_row, start_col:end_col])\n",
    "        # else extract the ROI with less padding\n",
    "        else:\n",
    "            if debug:\n",
    "                print(\"ROI Big\", mask)\n",
    "            # padding for the random cropping\n",
    "            adj_mask_H = int(np.max([full_size * 1.15, mask_H]))\n",
    "            adj_mask_W = int(np.max([full_size * 1.15, mask_W]))\n",
    "            start_row = np.max([ctr_row - (adj_mask_H // 2), 0])\n",
    "            end_row = start_row + adj_mask_H\n",
    "            if end_row > img_h:\n",
    "                end_row = img_h\n",
    "                start_row = img_h - adj_mask_H\n",
    "            start_col = np.max([ctr_col - (adj_mask_W // 2), 0])\n",
    "            end_col = start_col + adj_mask_W\n",
    "            if end_col > img_w:\n",
    "                end_col = img_w\n",
    "                start_col = img_w - adj_mask_W\n",
    "            # extract the ROI and randomly flip it\n",
    "            roi_img = random_flip_img_train(full_img_arr[start_row:end_row, start_col:end_col])\n",
    "              \n",
    "        patch_1 = crop_img(roi_img)\n",
    "        patch_2 = crop_img(roi_img)\n",
    "        patch_3 = crop_img(roi_img)\n",
    "         \n",
    "        if (patch_1.shape[0] == size) and (patch_1.shape[1] == size):\n",
    "            patch_list.append(patch_1)\n",
    "            Lbl_list.append(Lbl)\n",
    "            FN_list.append(base_img_file)\n",
    "                \n",
    "        if (patch_2.shape[0] == size) and (patch_2.shape[1] == size):\n",
    "            patch_list.append(patch_2)\n",
    "            Lbl_list.append(Lbl)\n",
    "            FN_list.append(base_img_file)\n",
    "        \n",
    "        if (patch_3.shape[0] == size) and (patch_2.shape[1] == size):\n",
    "            patch_list.append(patch_3)\n",
    "            Lbl_list.append(Lbl)\n",
    "            FN_list.append(base_img_file)\n",
    "                \n",
    "    return np.array(patch_list), np.array(Lbl_list), np.array(FN_list), roi_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1546 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming borders D:/mammography/mask/train_png/Calc/Calc-Training_P_00005_RIGHT_CC_1.png\n",
      "Mask Calc-Training_P_00005_RIGHT_CC_1.png  Height: 549 Width: 637\n",
      "ROI Big Calc-Training_P_00005_RIGHT_CC_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3923: error: (-215:Assertion failed) func != 0 in function 'cv::hal::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-89b1415a02e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtrain_calc_patch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_calc_Lbl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_calc_FN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_calc_roi_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mcreate_patches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLbls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-d76ad5200b4c>\u001b[0m in \u001b[0;36mcreate_patches\u001b[1;34m(mask_dir, img_dir, Lbls, size, debug)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mroi_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_flip_img_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_img_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_row\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mpatch_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mpatch_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mpatch_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-88c7cbb66115>\u001b[0m in \u001b[0;36mcrop_img\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcropped_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcropped_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# resize it and return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mcropped_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcropped_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3923: error: (-215:Assertion failed) func != 0 in function 'cv::hal::resize'\n"
     ]
    }
   ],
   "source": [
    "train_labels = pd.read_pickle(\"label old ver/train_label.pkl\")\n",
    "train_labels['IMAGE_NAME2'] = train_labels.index\n",
    "train_labels = train_labels.drop_duplicates(['IMAGE_NAME2'])\n",
    "## use a copy on the local drive to make testing faster\n",
    "mask_dir = \"D:/mammography/mask/train_png/Calc\"\n",
    "img_dir = \"D:/mammography/full/train_png/Calc\"\n",
    "\n",
    "train_calc_patch, train_calc_Lbl, train_calc_FN, train_calc_roi_size = \\\n",
    "        create_patches(mask_dir, img_dir, Lbls=train_labels, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calc_training\n",
    "train_labels = pd.read_pickle(\"label old ver/train_label.pkl\")\n",
    "train_labels['IMAGE_NAME2'] = train_labels.index\n",
    "train_labels = train_labels.drop_duplicates(['IMAGE_NAME2'])\n",
    "\n",
    "## use a copy on the local drive to make testing faster\n",
    "mask_dir = \"D:/mammography/mask/train_png/Calc\"\n",
    "img_dir = \"D:/mammography/full/train_png/Calc\"\n",
    "\n",
    "roi_sizes = []\n",
    "\n",
    "train_calc_patch, train_calc_Lbl, train_calc_FN, train_calc_roi_size = \\\n",
    "    create_patches(roi_sizes, mask_dir, img_dir, Lbls=train_labels, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
