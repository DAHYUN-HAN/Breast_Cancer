{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "#from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adadelta, Adagrad, Adamax, Nadam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization, GlobalAveragePooling2D  \n",
    "from tensorflow.keras.backend import batch_normalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from packaging import version\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training():\n",
    "    \"\"\"\n",
    "    Load the training set (excluding baseline patches)\n",
    "    \"\"\"\n",
    "    images = np.load(os.path.join('Data_again', 'X_train.npy'))\n",
    "    labels = np.load(os.path.join('Data_again', 'train_labels_multi.npy'))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_testing():\n",
    "    \"\"\"\n",
    "    Load the test set (abnormalities patches and labels, no baseline)\n",
    "    \"\"\"\n",
    "    images = np.load(os.path.join('Data_again', 'X_test.npy'))\n",
    "    labels = np.load(os.path.join('Data_again', 'y_test_labels_multi.npy'))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def remap_label(l):\n",
    "    \"\"\"\n",
    "    Remap the labels to:\n",
    "        0 -> mass benign \n",
    "        1 -> mass malignant\n",
    "        2 -> calcification benign\n",
    "        3 -> calcification malignant\n",
    "    \"\"\"\n",
    "    if 1 <= l <= 4:\n",
    "        return l-1\n",
    "    else:\n",
    "        print(\"[WARN] Unrecognized label (%d)\" % l)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2913 \t Test size: 655\n",
      "Image size: 256x256\n"
     ]
    }
   ],
   "source": [
    "# Load training and test images (abnormalities only, no baseline)\n",
    "train_images, train_labels= load_training()\n",
    "test_images, test_labels= load_testing()\n",
    "\n",
    "# Number of images\n",
    "n_train_img = train_images.shape[0]\n",
    "n_test_img = test_images.shape[0]\n",
    "print(\"Train size: %d \\t Test size: %d\" % (n_train_img, n_test_img))\n",
    "\n",
    "# Compute width and height of images\n",
    "img_w = train_images.shape[1]\n",
    "img_h = train_images.shape[2]\n",
    "print(\"Image size: %dx%d\" % (img_w, img_h))\n",
    "\n",
    "# Convert the labels to categorical format\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels_raw = test_labels.copy()\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Create a new dimension for color in the images arrays\n",
    "train_images = train_images.reshape((n_train_img, img_w, img_h, 1))\n",
    "test_images = test_images.reshape((n_test_img, img_w, img_h, 1))\n",
    "\n",
    "# Convert from 16-bit (0-65535) to to 8-bit (0-255)\n",
    "train_images = train_images.astype('uint16') / 255\n",
    "test_images = test_images.astype('uint16') / 255\n",
    "\n",
    "# Replicate the only color channel (gray) 3 times, for VGGNet compatibility\n",
    "train_images = np.repeat(train_images, 3, axis=3)\n",
    "test_images = np.repeat(test_images, 3, axis=3)\n",
    "\n",
    "# Shuffle the training set (originally sorted by label)\n",
    "perm = np.random.permutation(n_train_img)\n",
    "train_images = train_images[perm]\n",
    "train_labels = train_labels[perm]\n",
    "\n",
    "# Create a generator for training images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=180,\n",
    "    shear_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# Fit the generator with some images\n",
    "train_datagen.fit(train_images)\n",
    "\n",
    "# Split train images into actual training and validation\n",
    "train_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='training')\n",
    "validation_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='validation')\n",
    "\n",
    "# Preprocess the test images as well\n",
    "preprocess_input(test_images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using VGG16 convolutional base and new FC final layer\n",
    "\n",
    "def create_inceptionv3(verbose=False, fc_size=256, dropout=None):\n",
    "    \n",
    "    inceptionv3_base = InceptionV3(weights='imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(256, 256, 3))\n",
    "    inceptionv3 = models.Sequential()\n",
    "    inceptionv3.add(inceptionv3_base)\n",
    "\n",
    "    inceptionv3.add(layers.Flatten())\n",
    "    if dropout is not None:\n",
    "        inceptionv3.add(layers.Dropout(dropout))\n",
    "    inceptionv3.add(layers.Dense(fc_size, activation='relu'))\n",
    "    inceptionv3.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "    # Freeze the convolutional base\n",
    "    inceptionv3_base.trainable = False\n",
    "    \n",
    "    if verbose:\n",
    "        inceptionv3_base.summary()\n",
    "        inceptionv3.summary()\n",
    "\n",
    "    return inceptionv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 29, 29, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 29, 29, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 29, 29, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 29, 29, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 29, 29, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 29, 29, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 29, 29, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 29, 29, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 29, 29, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 29, 29, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 29, 29, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 29, 29, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 29, 29, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 29, 29, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 29, 29, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 29, 29, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 29, 29, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 29, 29, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 29, 29, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 29, 29, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 29, 29, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 29, 29, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 29, 29, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 29, 29, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 29, 29, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 29, 29, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 29, 29, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 29, 29, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 29, 29, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 14, 14, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 14, 14, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 14, 14, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 14, 14, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 14, 14, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 14, 14, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 14, 14, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 14, 14, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 14, 14, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 14, 14, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 14, 14, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 14, 14, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 14, 14, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 14, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 14, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 14, 14, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 14, 14, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 14, 14, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 14, 14, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 14, 14, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 14, 14, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 14, 14, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 14, 14, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 6, 6, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 40,678,436\n",
      "Trainable params: 18,875,652\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inceptionv3_fe_drop_temp = create_inceptionv3(verbose=True, dropout=0.5, fc_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a VGG19 network with custom final layer\n",
    "inceptionv3_fe_drop_128 = create_inceptionv3(dropout=0.5, fc_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 6, 6, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               9437312   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 31,240,612\n",
      "Trainable params: 9,437,828\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inceptionv3_fe_drop_128.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping (stop training after the validation loss reaches the minimum)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=30, verbose=1)\n",
    "\n",
    "# Callback for checkpointing\n",
    "checkpoint = ModelCheckpoint('inceptionv3_fe_drop_128_4cl_best.h5', \n",
    "        monitor='val_loss', mode='min', verbose=1, \n",
    "        save_best_only=True, save_freq='epoch'\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "inceptionv3_fe_drop_128.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-ff69acd8fde4>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 19 steps, validate for 5 steps\n",
      "Epoch 1/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 18.0730 - accuracy: 0.3209\n",
      "Epoch 00001: val_loss improved from inf to 22.40103, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 35s 2s/step - loss: 17.3521 - accuracy: 0.3192 - val_loss: 22.4010 - val_accuracy: 0.2423\n",
      "Epoch 2/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.9389 - accuracy: 0.3418\n",
      "Epoch 00002: val_loss improved from 22.40103 to 7.05765, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.9073 - accuracy: 0.3402 - val_loss: 7.0577 - val_accuracy: 0.2062\n",
      "Epoch 3/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.4070 - accuracy: 0.3182\n",
      "Epoch 00003: val_loss did not improve from 7.05765\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3989 - accuracy: 0.3196 - val_loss: 16.2113 - val_accuracy: 0.2062\n",
      "Epoch 4/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3829 - accuracy: 0.3336\n",
      "Epoch 00004: val_loss improved from 7.05765 to 1.38372, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3823 - accuracy: 0.3363 - val_loss: 1.3837 - val_accuracy: 0.3368\n",
      "Epoch 5/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3850 - accuracy: 0.3414\n",
      "Epoch 00005: val_loss did not improve from 1.38372\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3827 - accuracy: 0.3415 - val_loss: 8.8180 - val_accuracy: 0.3368\n",
      "Epoch 6/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3997 - accuracy: 0.3427\n",
      "Epoch 00006: val_loss improved from 1.38372 to 1.38020, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3986 - accuracy: 0.3402 - val_loss: 1.3802 - val_accuracy: 0.3368\n",
      "Epoch 7/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3767 - accuracy: 0.3404\n",
      "Epoch 00007: val_loss improved from 1.38020 to 1.37824, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3768 - accuracy: 0.3402 - val_loss: 1.3782 - val_accuracy: 0.3368\n",
      "Epoch 8/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3746 - accuracy: 0.3382\n",
      "Epoch 00008: val_loss improved from 1.37824 to 1.37650, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3744 - accuracy: 0.3402 - val_loss: 1.3765 - val_accuracy: 0.3368\n",
      "Epoch 9/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3724 - accuracy: 0.3382\n",
      "Epoch 00009: val_loss improved from 1.37650 to 1.37494, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3722 - accuracy: 0.3402 - val_loss: 1.3749 - val_accuracy: 0.3368\n",
      "Epoch 10/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3706 - accuracy: 0.3404\n",
      "Epoch 00010: val_loss improved from 1.37494 to 1.37357, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3701 - accuracy: 0.3402 - val_loss: 1.3736 - val_accuracy: 0.3368\n",
      "Epoch 11/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3687 - accuracy: 0.3377\n",
      "Epoch 00011: val_loss improved from 1.37357 to 1.37227, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3682 - accuracy: 0.3402 - val_loss: 1.3723 - val_accuracy: 0.3368\n",
      "Epoch 12/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3668 - accuracy: 0.3382\n",
      "Epoch 00012: val_loss improved from 1.37227 to 1.37124, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3665 - accuracy: 0.3402 - val_loss: 1.3712 - val_accuracy: 0.3368\n",
      "Epoch 13/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.4358 - accuracy: 0.3427\n",
      "Epoch 00013: val_loss improved from 1.37124 to 1.37080, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.4325 - accuracy: 0.3402 - val_loss: 1.3708 - val_accuracy: 0.3368\n",
      "Epoch 14/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3638 - accuracy: 0.3400\n",
      "Epoch 00014: val_loss improved from 1.37080 to 1.37005, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3642 - accuracy: 0.3398 - val_loss: 1.3700 - val_accuracy: 0.3368\n",
      "Epoch 15/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3621 - accuracy: 0.3432\n",
      "Epoch 00015: val_loss improved from 1.37005 to 1.36930, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3630 - accuracy: 0.3402 - val_loss: 1.3693 - val_accuracy: 0.3368\n",
      "Epoch 16/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3616 - accuracy: 0.3391\n",
      "Epoch 00016: val_loss did not improve from 1.36930\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3617 - accuracy: 0.3402 - val_loss: 9.1049 - val_accuracy: 0.3368\n",
      "Epoch 17/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3623 - accuracy: 0.3377\n",
      "Epoch 00017: val_loss improved from 1.36930 to 1.36830, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3616 - accuracy: 0.3402 - val_loss: 1.3683 - val_accuracy: 0.3368\n",
      "Epoch 18/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3601 - accuracy: 0.3391\n",
      "Epoch 00018: val_loss improved from 1.36830 to 1.36790, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3600 - accuracy: 0.3402 - val_loss: 1.3679 - val_accuracy: 0.3368\n",
      "Epoch 19/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3597 - accuracy: 0.3382\n",
      "Epoch 00019: val_loss improved from 1.36790 to 1.36757, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3592 - accuracy: 0.3402 - val_loss: 1.3676 - val_accuracy: 0.3368\n",
      "Epoch 20/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3594 - accuracy: 0.3391\n",
      "Epoch 00020: val_loss improved from 1.36757 to 1.36732, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3585 - accuracy: 0.3402 - val_loss: 1.3673 - val_accuracy: 0.3368\n",
      "Epoch 21/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3583 - accuracy: 0.3403\n",
      "Epoch 00021: val_loss improved from 1.36732 to 1.36718, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3580 - accuracy: 0.3402 - val_loss: 1.3672 - val_accuracy: 0.3368\n",
      "Epoch 22/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3579 - accuracy: 0.3403\n",
      "Epoch 00022: val_loss improved from 1.36718 to 1.36707, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3575 - accuracy: 0.3402 - val_loss: 1.3671 - val_accuracy: 0.3368\n",
      "Epoch 23/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3564 - accuracy: 0.3427\n",
      "Epoch 00023: val_loss improved from 1.36707 to 1.36705, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3571 - accuracy: 0.3402 - val_loss: 1.3670 - val_accuracy: 0.3368\n",
      "Epoch 24/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3553 - accuracy: 0.3432\n",
      "Epoch 00024: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3568 - accuracy: 0.3402 - val_loss: 1.3671 - val_accuracy: 0.3368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3559 - accuracy: 0.3404\n",
      "Epoch 00025: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3565 - accuracy: 0.3402 - val_loss: 1.3671 - val_accuracy: 0.3368\n",
      "Epoch 26/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3574 - accuracy: 0.3404\n",
      "Epoch 00026: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3563 - accuracy: 0.3402 - val_loss: 1.3672 - val_accuracy: 0.3368\n",
      "Epoch 27/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3544 - accuracy: 0.3450\n",
      "Epoch 00027: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3561 - accuracy: 0.3402 - val_loss: 1.3672 - val_accuracy: 0.3368\n",
      "Epoch 28/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3560 - accuracy: 0.3404\n",
      "Epoch 00028: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3560 - accuracy: 0.3402 - val_loss: 1.3673 - val_accuracy: 0.3368\n",
      "Epoch 29/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3565 - accuracy: 0.3382\n",
      "Epoch 00029: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3559 - accuracy: 0.3402 - val_loss: 1.3674 - val_accuracy: 0.3368\n",
      "Epoch 30/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3540 - accuracy: 0.3432\n",
      "Epoch 00030: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3558 - accuracy: 0.3402 - val_loss: 1.3676 - val_accuracy: 0.3368\n",
      "Epoch 31/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3550 - accuracy: 0.3414\n",
      "Epoch 00031: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3557 - accuracy: 0.3402 - val_loss: 1.3677 - val_accuracy: 0.3368\n",
      "Epoch 32/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3567 - accuracy: 0.3391\n",
      "Epoch 00032: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3556 - accuracy: 0.3402 - val_loss: 1.3678 - val_accuracy: 0.3368\n",
      "Epoch 33/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3568 - accuracy: 0.3404\n",
      "Epoch 00033: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3556 - accuracy: 0.3402 - val_loss: 1.3679 - val_accuracy: 0.3368\n",
      "Epoch 34/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3555 - accuracy: 0.3382\n",
      "Epoch 00034: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3556 - accuracy: 0.3402 - val_loss: 1.3680 - val_accuracy: 0.3368\n",
      "Epoch 35/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3548 - accuracy: 0.3427\n",
      "Epoch 00035: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3555 - accuracy: 0.3402 - val_loss: 1.3681 - val_accuracy: 0.3368\n",
      "Epoch 36/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3567 - accuracy: 0.3400\n",
      "Epoch 00036: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3565 - accuracy: 0.3402 - val_loss: 1.3683 - val_accuracy: 0.3368\n",
      "Epoch 37/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3548 - accuracy: 0.3404\n",
      "Epoch 00037: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3555 - accuracy: 0.3402 - val_loss: 1.3683 - val_accuracy: 0.3368\n",
      "Epoch 38/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3556 - accuracy: 0.3400\n",
      "Epoch 00038: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3555 - accuracy: 0.3402 - val_loss: 1.3684 - val_accuracy: 0.3368\n",
      "Epoch 39/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3555 - accuracy: 0.3400\n",
      "Epoch 00039: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3555 - accuracy: 0.3402 - val_loss: 1.3685 - val_accuracy: 0.3368\n",
      "Epoch 40/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.4218 - accuracy: 0.3404\n",
      "Epoch 00040: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.4159 - accuracy: 0.3402 - val_loss: 1.3685 - val_accuracy: 0.3368\n",
      "Epoch 41/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3566 - accuracy: 0.3391\n",
      "Epoch 00041: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3686 - val_accuracy: 0.3368\n",
      "Epoch 42/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3535 - accuracy: 0.3432\n",
      "Epoch 00042: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3686 - val_accuracy: 0.3368\n",
      "Epoch 43/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3567 - accuracy: 0.3404\n",
      "Epoch 00043: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3687 - val_accuracy: 0.3368\n",
      "Epoch 44/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3565 - accuracy: 0.3377\n",
      "Epoch 00044: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3687 - val_accuracy: 0.3368\n",
      "Epoch 45/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3564 - accuracy: 0.3377\n",
      "Epoch 00045: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3688 - val_accuracy: 0.3368\n",
      "Epoch 46/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3555 - accuracy: 0.3391\n",
      "Epoch 00046: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3688 - val_accuracy: 0.3368\n",
      "Epoch 47/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3567 - accuracy: 0.3404\n",
      "Epoch 00047: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3689 - val_accuracy: 0.3368\n",
      "Epoch 48/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3566 - accuracy: 0.3391\n",
      "Epoch 00048: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3689 - val_accuracy: 0.3368\n",
      "Epoch 49/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3555 - accuracy: 0.3391\n",
      "Epoch 00049: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3689 - val_accuracy: 0.3368\n",
      "Epoch 50/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3565 - accuracy: 0.3377\n",
      "Epoch 00050: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3690 - val_accuracy: 0.3368\n",
      "Epoch 51/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3554 - accuracy: 0.3404\n",
      "Epoch 00051: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3690 - val_accuracy: 0.3368\n",
      "Epoch 52/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3555 - accuracy: 0.3391\n",
      "Epoch 00052: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3690 - val_accuracy: 0.3368\n",
      "Epoch 53/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3566 - accuracy: 0.3391\n",
      "Epoch 00053: val_loss did not improve from 1.36705\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3554 - accuracy: 0.3402 - val_loss: 1.3690 - val_accuracy: 0.3368\n",
      "Epoch 00053: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history_inceptionv3_fe_drop_128 = inceptionv3_fe_drop_128.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=200,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[checkpoint, earlystopping],\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "models.save_model(inceptionv3_fe_drop_128, 'inceptionv3_fe_drop_128_4cl_end.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# History of accuracy and loss\n",
    "tra_loss_fe = history_inceptionv3_fe_drop_128.history['loss']\n",
    "tra_acc_fe = history_inceptionv3_fe_drop_128.history['accuracy']\n",
    "val_loss_fe = history_inceptionv3_fe_drop_128.history['val_loss']\n",
    "val_acc_fe = history_inceptionv3_fe_drop_128.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of epochs training\n",
    "epochs_fe = range(1, len(tra_acc_fe)+1)\n",
    "end_epoch_fe = len(tra_acc_fe)\n",
    "\n",
    "# Epoch when reached the validation loss minimum\n",
    "opt_epoch_fe = val_loss_fe.index(min(val_loss_fe)) + 1\n",
    "\n",
    "# Loss and accuracy on the validation set\n",
    "end_val_loss_fe = val_loss_fe[-1]\n",
    "end_val_acc_fe = val_acc_fe[-1]\n",
    "opt_val_loss_fe = val_loss_fe[opt_epoch_fe-1]\n",
    "opt_val_acc_fe = val_acc_fe[opt_epoch_fe-1]\n",
    "\n",
    "# Loss and accuracy on the test set\n",
    "opt_inceptionv3_fe_drop_128 = models.load_model('inceptionv3_fe_drop_128_4cl_best.h5')\n",
    "test_loss_fe, test_acc_fe = inceptionv3_fe_drop_128.evaluate(test_images, test_labels, verbose=False)\n",
    "opt_test_loss_fe, opt_test_acc_fe = opt_inceptionv3_fe_drop_128.evaluate(test_images, test_labels, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inceptionv3 (w/ dropout, smaller FC) Feature Extraction\n",
      "\n",
      "Epoch [end]: 53\n",
      "Epoch [opt]: 23\n",
      "Valid accuracy [end]: 0.3368\n",
      "Valid accuracy [opt]: 0.3368\n",
      "Test accuracy [end]:  0.3191\n",
      "Test accuracy [opt]:  0.3191\n",
      "Valid loss [end]: 1.3690\n",
      "Valid loss [opt]: 1.3670\n",
      "Test loss [end]:  1.3845\n",
      "Test loss [opt]:  1.3784\n"
     ]
    }
   ],
   "source": [
    "print(\"inceptionv3 (w/ dropout, smaller FC) Feature Extraction\\n\")\n",
    "\n",
    "print(\"Epoch [end]: %d\" % end_epoch_fe)\n",
    "print(\"Epoch [opt]: %d\" % opt_epoch_fe)\n",
    "print(\"Valid accuracy [end]: %.4f\" % end_val_acc_fe)\n",
    "print(\"Valid accuracy [opt]: %.4f\" % opt_val_acc_fe)\n",
    "print(\"Test accuracy [end]:  %.4f\" % test_acc_fe)\n",
    "print(\"Test accuracy [opt]:  %.4f\" % opt_test_acc_fe)\n",
    "print(\"Valid loss [end]: %.4f\" % end_val_loss_fe)\n",
    "print(\"Valid loss [opt]: %.4f\" % opt_val_loss_fe)\n",
    "print(\"Test loss [end]:  %.4f\" % test_loss_fe)\n",
    "print(\"Test loss [opt]:  %.4f\" % opt_test_loss_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 560x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 560x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model accuracy\n",
    "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.title('inceptionv3 w/ dropout FC 128 FE accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs_fe, tra_acc_fe, 'r', label='Training set')\n",
    "plt.plot(epochs_fe, val_acc_fe, 'g', label='Validation set')\n",
    "plt.plot(opt_epoch_fe, val_acc_fe[opt_epoch_fe-1], 'go')\n",
    "plt.vlines(opt_epoch_fe, min(val_acc_fe), opt_val_acc_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.hlines(opt_val_acc_fe, 1, opt_epoch_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Model loss\n",
    "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.title('inceptionv3 w/ dropout FC 128 FE loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs_fe, tra_loss_fe, 'r', label='Training set')\n",
    "plt.plot(epochs_fe, val_loss_fe, 'g', label='Validation set')\n",
    "plt.plot(opt_epoch_fe, val_loss_fe[opt_epoch_fe-1], 'go')\n",
    "plt.vlines(opt_epoch_fe, min(val_loss_fe), opt_val_loss_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.hlines(opt_val_loss_fe, 1, opt_epoch_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
