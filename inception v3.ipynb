{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "#from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adadelta, Adagrad, Adamax, Nadam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization, GlobalAveragePooling2D  \n",
    "from tensorflow.keras.backend import batch_normalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from packaging import version\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training():\n",
    "    \"\"\"\n",
    "    Load the training set (excluding baseline patches)\n",
    "    \"\"\"\n",
    "    images = np.load(os.path.join('Data_new3', 'X_train.npy'))\n",
    "    labels = np.load(os.path.join('Data_new3', 'train_labels_multi.npy'))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_testing():\n",
    "    \"\"\"\n",
    "    Load the test set (abnormalities patches and labels, no baseline)\n",
    "    \"\"\"\n",
    "    images = np.load(os.path.join('Data_new3', 'X_test.npy'))\n",
    "    labels = np.load(os.path.join('Data_new3', 'y_test_labels_multi.npy'))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def remap_label(l):\n",
    "    \"\"\"\n",
    "    Remap the labels to:\n",
    "        0 -> mass benign \n",
    "        1 -> mass malignant\n",
    "        2 -> calcification benign\n",
    "        3 -> calcification malignant\n",
    "    \"\"\"\n",
    "    if 1 <= l <= 4:\n",
    "        return l-1\n",
    "    else:\n",
    "        print(\"[WARN] Unrecognized label (%d)\" % l)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2913 \t Test size: 655\n",
      "Image size: 256x256\n"
     ]
    }
   ],
   "source": [
    "# Load training and test images (abnormalities only, no baseline)\n",
    "train_images, train_labels= load_training()\n",
    "test_images, test_labels= load_testing()\n",
    "\n",
    "# Number of images\n",
    "n_train_img = train_images.shape[0]\n",
    "n_test_img = test_images.shape[0]\n",
    "print(\"Train size: %d \\t Test size: %d\" % (n_train_img, n_test_img))\n",
    "\n",
    "# Compute width and height of images\n",
    "img_w = train_images.shape[1]\n",
    "img_h = train_images.shape[2]\n",
    "print(\"Image size: %dx%d\" % (img_w, img_h))\n",
    "\n",
    "# Convert the labels to categorical format\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels_raw = test_labels.copy()\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Create a new dimension for color in the images arrays\n",
    "train_images = train_images.reshape((n_train_img, img_w, img_h, 1))\n",
    "test_images = test_images.reshape((n_test_img, img_w, img_h, 1))\n",
    "\n",
    "# Convert from 16-bit (0-65535) to to 8-bit (0-255)\n",
    "train_images = train_images.astype('uint16') / 255\n",
    "test_images = test_images.astype('uint16') / 255\n",
    "\n",
    "# Replicate the only color channel (gray) 3 times, for VGGNet compatibility\n",
    "train_images = np.repeat(train_images, 3, axis=3)\n",
    "test_images = np.repeat(test_images, 3, axis=3)\n",
    "\n",
    "# Shuffle the training set (originally sorted by label)\n",
    "perm = np.random.permutation(n_train_img)\n",
    "train_images = train_images[perm]\n",
    "train_labels = train_labels[perm]\n",
    "\n",
    "# Create a generator for training images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=180,\n",
    "    shear_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# Fit the generator with some images\n",
    "train_datagen.fit(train_images)\n",
    "\n",
    "# Split train images into actual training and validation\n",
    "train_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='training')\n",
    "validation_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='validation')\n",
    "\n",
    "# Preprocess the test images as well\n",
    "preprocess_input(test_images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using VGG16 convolutional base and new FC final layer\n",
    "\n",
    "def create_inceptionv3(verbose=False, fc_size=256, dropout=None):\n",
    "    \n",
    "    inceptionv3_base = InceptionV3(weights='imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(256, 256, 3))\n",
    "    inceptionv3 = models.Sequential()\n",
    "    inceptionv3.add(inceptionv3_base)\n",
    "\n",
    "    inceptionv3.add(layers.Flatten())\n",
    "    if dropout is not None:\n",
    "        inceptionv3.add(layers.Dropout(dropout))\n",
    "    inceptionv3.add(layers.Dense(fc_size, activation='relu'))\n",
    "    inceptionv3.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "    # Freeze the convolutional base\n",
    "    inceptionv3_base.trainable = False\n",
    "    \n",
    "    if verbose:\n",
    "        inceptionv3_base.summary()\n",
    "        inceptionv3.summary()\n",
    "\n",
    "    return inceptionv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 29, 29, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 29, 29, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 29, 29, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 29, 29, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 29, 29, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 29, 29, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 29, 29, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 29, 29, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 29, 29, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 29, 29, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 29, 29, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 29, 29, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 29, 29, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 29, 29, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 29, 29, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 29, 29, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 29, 29, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 29, 29, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 29, 29, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 29, 29, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 29, 29, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 29, 29, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 29, 29, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 29, 29, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 29, 29, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 29, 29, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 29, 29, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 29, 29, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 29, 29, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 14, 14, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 14, 14, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 14, 14, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 14, 14, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 14, 14, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 14, 14, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 14, 14, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 14, 14, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 14, 14, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 14, 14, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 14, 14, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 14, 14, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 14, 14, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 14, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 14, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 14, 14, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 14, 14, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 14, 14, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 14, 14, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 14, 14, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 14, 14, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 14, 14, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 14, 14, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 6, 6, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 40,678,436\n",
      "Trainable params: 18,875,652\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inceptionv3_fe_drop_temp = create_inceptionv3(verbose=True, dropout=0.5, fc_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a VGG19 network with custom final layer\n",
    "inceptionv3_fe_drop_128 = create_inceptionv3(dropout=0.5, fc_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 6, 6, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               9437312   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 31,240,612\n",
      "Trainable params: 9,437,828\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inceptionv3_fe_drop_128.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping (stop training after the validation loss reaches the minimum)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=30, verbose=1)\n",
    "\n",
    "# Callback for checkpointing\n",
    "checkpoint = ModelCheckpoint('inceptionv3_fe_drop_128_4cl_best.h5', \n",
    "        monitor='val_loss', mode='min', verbose=1, \n",
    "        save_best_only=True, save_freq='epoch'\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "inceptionv3_fe_drop_128.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-ff69acd8fde4>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 19 steps, validate for 5 steps\n",
      "Epoch 1/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 14.3310 - accuracy: 0.2574\n",
      "Epoch 00001: val_loss improved from inf to 1.70922, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 35s 2s/step - loss: 13.6757 - accuracy: 0.2634 - val_loss: 1.7092 - val_accuracy: 0.3351\n",
      "Epoch 2/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3915 - accuracy: 0.3500\n",
      "Epoch 00002: val_loss improved from 1.70922 to 1.38423, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3911 - accuracy: 0.3458 - val_loss: 1.3842 - val_accuracy: 0.3505\n",
      "Epoch 3/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3910 - accuracy: 0.3432\n",
      "Epoch 00003: val_loss improved from 1.38423 to 1.38224, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3904 - accuracy: 0.3479 - val_loss: 1.3822 - val_accuracy: 0.3505\n",
      "Epoch 4/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3831 - accuracy: 0.3359\n",
      "Epoch 00004: val_loss improved from 1.38224 to 1.37990, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3827 - accuracy: 0.3398 - val_loss: 1.3799 - val_accuracy: 0.3505\n",
      "Epoch 5/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3785 - accuracy: 0.3477\n",
      "Epoch 00005: val_loss did not improve from 1.37990\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3783 - accuracy: 0.3479 - val_loss: 1.4559 - val_accuracy: 0.3505\n",
      "Epoch 6/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3823 - accuracy: 0.3472\n",
      "Epoch 00006: val_loss did not improve from 1.37990\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3802 - accuracy: 0.3479 - val_loss: 23.3512 - val_accuracy: 0.1959\n",
      "Epoch 7/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.4408 - accuracy: 0.3468\n",
      "Epoch 00007: val_loss improved from 1.37990 to 1.37432, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.4375 - accuracy: 0.3462 - val_loss: 1.3743 - val_accuracy: 0.3505\n",
      "Epoch 8/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3724 - accuracy: 0.3486\n",
      "Epoch 00008: val_loss improved from 1.37432 to 1.37250, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3727 - accuracy: 0.3479 - val_loss: 1.3725 - val_accuracy: 0.3505\n",
      "Epoch 9/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3768 - accuracy: 0.3468\n",
      "Epoch 00009: val_loss improved from 1.37250 to 1.37101, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3764 - accuracy: 0.3479 - val_loss: 1.3710 - val_accuracy: 0.3505\n",
      "Epoch 10/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3693 - accuracy: 0.3468\n",
      "Epoch 00010: val_loss improved from 1.37101 to 1.36947, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3692 - accuracy: 0.3479 - val_loss: 1.3695 - val_accuracy: 0.3505\n",
      "Epoch 11/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3683 - accuracy: 0.3445\n",
      "Epoch 00011: val_loss improved from 1.36947 to 1.36806, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3676 - accuracy: 0.3479 - val_loss: 1.3681 - val_accuracy: 0.3505\n",
      "Epoch 12/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.4913 - accuracy: 0.3427\n",
      "Epoch 00012: val_loss improved from 1.36806 to 1.36771, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.4840 - accuracy: 0.3479 - val_loss: 1.3677 - val_accuracy: 0.3505\n",
      "Epoch 13/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3694 - accuracy: 0.3482\n",
      "Epoch 00013: val_loss improved from 1.36771 to 1.36681, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3697 - accuracy: 0.3475 - val_loss: 1.3668 - val_accuracy: 0.3505\n",
      "Epoch 14/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3659 - accuracy: 0.3432\n",
      "Epoch 00014: val_loss improved from 1.36681 to 1.36585, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3649 - accuracy: 0.3479 - val_loss: 1.3658 - val_accuracy: 0.3505\n",
      "Epoch 15/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3691 - accuracy: 0.3513\n",
      "Epoch 00015: val_loss improved from 1.36585 to 1.36551, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3693 - accuracy: 0.3488 - val_loss: 1.3655 - val_accuracy: 0.3488\n",
      "Epoch 16/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3645 - accuracy: 0.3468\n",
      "Epoch 00016: val_loss improved from 1.36551 to 1.36415, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3639 - accuracy: 0.3475 - val_loss: 1.3642 - val_accuracy: 0.3505\n",
      "Epoch 17/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3627 - accuracy: 0.3459\n",
      "Epoch 00017: val_loss improved from 1.36415 to 1.36350, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3621 - accuracy: 0.3479 - val_loss: 1.3635 - val_accuracy: 0.3505\n",
      "Epoch 18/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3618 - accuracy: 0.3463\n",
      "Epoch 00018: val_loss improved from 1.36350 to 1.36290, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3614 - accuracy: 0.3479 - val_loss: 1.3629 - val_accuracy: 0.3505\n",
      "Epoch 19/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3611 - accuracy: 0.3477\n",
      "Epoch 00019: val_loss improved from 1.36290 to 1.36247, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3608 - accuracy: 0.3479 - val_loss: 1.3625 - val_accuracy: 0.3505\n",
      "Epoch 20/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3620 - accuracy: 0.3427\n",
      "Epoch 00020: val_loss improved from 1.36247 to 1.36205, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3603 - accuracy: 0.3479 - val_loss: 1.3621 - val_accuracy: 0.3505\n",
      "Epoch 21/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3653 - accuracy: 0.3427\n",
      "Epoch 00021: val_loss improved from 1.36205 to 1.36175, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3637 - accuracy: 0.3462 - val_loss: 1.3618 - val_accuracy: 0.3505\n",
      "Epoch 22/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3592 - accuracy: 0.3495\n",
      "Epoch 00022: val_loss improved from 1.36175 to 1.36151, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3595 - accuracy: 0.3479 - val_loss: 1.3615 - val_accuracy: 0.3505\n",
      "Epoch 23/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3611 - accuracy: 0.3427\n",
      "Epoch 00023: val_loss improved from 1.36151 to 1.36130, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3592 - accuracy: 0.3479 - val_loss: 1.3613 - val_accuracy: 0.3505\n",
      "Epoch 24/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3609 - accuracy: 0.3427\n",
      "Epoch 00024: val_loss improved from 1.36130 to 1.36115, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 30s 2s/step - loss: 1.3590 - accuracy: 0.3479 - val_loss: 1.3612 - val_accuracy: 0.3505\n",
      "Epoch 25/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3584 - accuracy: 0.3495\n",
      "Epoch 00025: val_loss improved from 1.36115 to 1.36104, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3588 - accuracy: 0.3479 - val_loss: 1.3610 - val_accuracy: 0.3505\n",
      "Epoch 26/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3570 - accuracy: 0.3522\n",
      "Epoch 00026: val_loss improved from 1.36104 to 1.36094, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3586 - accuracy: 0.3479 - val_loss: 1.3609 - val_accuracy: 0.3505\n",
      "Epoch 27/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3582 - accuracy: 0.3486\n",
      "Epoch 00027: val_loss improved from 1.36094 to 1.36088, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3585 - accuracy: 0.3479 - val_loss: 1.3609 - val_accuracy: 0.3505\n",
      "Epoch 28/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3581 - accuracy: 0.3491\n",
      "Epoch 00028: val_loss improved from 1.36088 to 1.36082, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3584 - accuracy: 0.3479 - val_loss: 1.3608 - val_accuracy: 0.3505\n",
      "Epoch 29/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3591 - accuracy: 0.3459\n",
      "Epoch 00029: val_loss improved from 1.36082 to 1.36078, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3583 - accuracy: 0.3479 - val_loss: 1.3608 - val_accuracy: 0.3505\n",
      "Epoch 30/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3597 - accuracy: 0.3445\n",
      "Epoch 00030: val_loss improved from 1.36078 to 1.36075, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3583 - accuracy: 0.3479 - val_loss: 1.3608 - val_accuracy: 0.3505\n",
      "Epoch 31/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3573 - accuracy: 0.3486\n",
      "Epoch 00031: val_loss improved from 1.36075 to 1.36073, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3582 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 32/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3578 - accuracy: 0.3491\n",
      "Epoch 00032: val_loss improved from 1.36073 to 1.36072, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3582 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 33/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3577 - accuracy: 0.3495\n",
      "Epoch 00033: val_loss improved from 1.36072 to 1.36071, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3581 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 34/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3585 - accuracy: 0.3477\n",
      "Epoch 00034: val_loss improved from 1.36071 to 1.36071, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3581 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 35/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3563 - accuracy: 0.3522\n",
      "Epoch 00035: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3581 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 36/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3566 - accuracy: 0.3495\n",
      "Epoch 00036: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3581 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 37/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3587 - accuracy: 0.3486\n",
      "Epoch 00037: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3580 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 38/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3576 - accuracy: 0.3495\n",
      "Epoch 00038: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3580 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 39/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3590 - accuracy: 0.3472\n",
      "Epoch 00039: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3580 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 40/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3576 - accuracy: 0.3486\n",
      "Epoch 00040: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3580 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 41/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3566 - accuracy: 0.3504\n",
      "Epoch 00041: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3580 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 42/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3602 - accuracy: 0.3427\n",
      "Epoch 00042: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3580 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 43/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3572 - accuracy: 0.3491\n",
      "Epoch 00043: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3580 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 44/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3576 - accuracy: 0.3491\n",
      "Epoch 00044: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3577 - accuracy: 0.3483 - val_loss: 1.5421 - val_accuracy: 0.3110\n",
      "Epoch 45/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3566 - accuracy: 0.3518\n",
      "Epoch 00045: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3584 - accuracy: 0.3475 - val_loss: 1.3692 - val_accuracy: 0.3505\n",
      "Epoch 46/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3587 - accuracy: 0.3491\n",
      "Epoch 00046: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3591 - accuracy: 0.3475 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 47/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3587 - accuracy: 0.3486\n",
      "Epoch 00047: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3579 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 48/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3554 - accuracy: 0.3504\n",
      "Epoch 00048: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3570 - accuracy: 0.3483 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 49/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3614 - accuracy: 0.3459\n",
      "Epoch 00049: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3605 - accuracy: 0.3475 - val_loss: 10.4198 - val_accuracy: 0.2354\n",
      "Epoch 50/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3676 - accuracy: 0.3486\n",
      "Epoch 00050: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3671 - accuracy: 0.3479 - val_loss: 1.3651 - val_accuracy: 0.3471\n",
      "Epoch 51/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3589 - accuracy: 0.3491\n",
      "Epoch 00051: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3592 - accuracy: 0.3475 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3575 - accuracy: 0.3486\n",
      "Epoch 00052: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3579 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 53/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3568 - accuracy: 0.3495\n",
      "Epoch 00053: val_loss did not improve from 1.36071\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3585 - accuracy: 0.3475 - val_loss: 1.3608 - val_accuracy: 0.3505\n",
      "Epoch 54/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3645 - accuracy: 0.3432\n",
      "Epoch 00054: val_loss improved from 1.36071 to 1.35993, saving model to inceptionv3_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3620 - accuracy: 0.3483 - val_loss: 1.3599 - val_accuracy: 0.3522\n",
      "Epoch 55/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3587 - accuracy: 0.3468\n",
      "Epoch 00055: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3586 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 56/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3589 - accuracy: 0.3472\n",
      "Epoch 00056: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3578 - accuracy: 0.3479 - val_loss: 1.4705 - val_accuracy: 0.3436\n",
      "Epoch 57/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3723 - accuracy: 0.3509\n",
      "Epoch 00057: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3723 - accuracy: 0.3483 - val_loss: 1.4095 - val_accuracy: 0.3419\n",
      "Epoch 58/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3636 - accuracy: 0.3504\n",
      "Epoch 00058: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3643 - accuracy: 0.3479 - val_loss: 1.3605 - val_accuracy: 0.3505\n",
      "Epoch 59/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3655 - accuracy: 0.3473\n",
      "Epoch 00059: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3647 - accuracy: 0.3475 - val_loss: 1.3677 - val_accuracy: 0.3505\n",
      "Epoch 60/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3572 - accuracy: 0.3504\n",
      "Epoch 00060: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3586 - accuracy: 0.3479 - val_loss: 1.3607 - val_accuracy: 0.3505\n",
      "Epoch 61/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3563 - accuracy: 0.3500\n",
      "Epoch 00061: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3579 - accuracy: 0.3479 - val_loss: 1.3705 - val_accuracy: 0.3505\n",
      "Epoch 62/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3631 - accuracy: 0.3477\n",
      "Epoch 00062: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3630 - accuracy: 0.3466 - val_loss: 1.6749 - val_accuracy: 0.3471\n",
      "Epoch 63/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3567 - accuracy: 0.3491\n",
      "Epoch 00063: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3580 - accuracy: 0.3479 - val_loss: 1.6948 - val_accuracy: 0.3454\n",
      "Epoch 64/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3554 - accuracy: 0.3500\n",
      "Epoch 00064: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3590 - accuracy: 0.3483 - val_loss: 1.7543 - val_accuracy: 0.3540\n",
      "Epoch 65/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3590 - accuracy: 0.3468\n",
      "Epoch 00065: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3587 - accuracy: 0.3479 - val_loss: 2.6871 - val_accuracy: 0.3505\n",
      "Epoch 66/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3550 - accuracy: 0.3486\n",
      "Epoch 00066: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3546 - accuracy: 0.3479 - val_loss: 5.6912 - val_accuracy: 0.3505\n",
      "Epoch 67/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3507 - accuracy: 0.3500\n",
      "Epoch 00067: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3516 - accuracy: 0.3479 - val_loss: 6.5775 - val_accuracy: 0.3505\n",
      "Epoch 68/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3421 - accuracy: 0.3504\n",
      "Epoch 00068: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3430 - accuracy: 0.3479 - val_loss: 7.0811 - val_accuracy: 0.3505\n",
      "Epoch 69/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3493 - accuracy: 0.3504\n",
      "Epoch 00069: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3500 - accuracy: 0.3479 - val_loss: 6.0095 - val_accuracy: 0.3505\n",
      "Epoch 70/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3454 - accuracy: 0.3459\n",
      "Epoch 00070: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3436 - accuracy: 0.3479 - val_loss: 10.8474 - val_accuracy: 0.3505\n",
      "Epoch 71/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3474 - accuracy: 0.3445\n",
      "Epoch 00071: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3443 - accuracy: 0.3479 - val_loss: 13.4888 - val_accuracy: 0.3505\n",
      "Epoch 72/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3459 - accuracy: 0.3463\n",
      "Epoch 00072: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3453 - accuracy: 0.3479 - val_loss: 11.0971 - val_accuracy: 0.3505\n",
      "Epoch 73/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3398 - accuracy: 0.3472\n",
      "Epoch 00073: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3366 - accuracy: 0.3479 - val_loss: 10.4455 - val_accuracy: 0.3505\n",
      "Epoch 74/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3401 - accuracy: 0.3445\n",
      "Epoch 00074: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3377 - accuracy: 0.3479 - val_loss: 13.2318 - val_accuracy: 0.3505\n",
      "Epoch 75/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3277 - accuracy: 0.3495\n",
      "Epoch 00075: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3275 - accuracy: 0.3479 - val_loss: 10.8196 - val_accuracy: 0.3505\n",
      "Epoch 76/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3279 - accuracy: 0.3491\n",
      "Epoch 00076: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3280 - accuracy: 0.3479 - val_loss: 11.8473 - val_accuracy: 0.3505\n",
      "Epoch 77/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3293 - accuracy: 0.3522\n",
      "Epoch 00077: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3311 - accuracy: 0.3479 - val_loss: 12.8046 - val_accuracy: 0.3505\n",
      "Epoch 78/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3332 - accuracy: 0.3500\n",
      "Epoch 00078: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3351 - accuracy: 0.3479 - val_loss: 9.1410 - val_accuracy: 0.3505\n",
      "Epoch 79/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3276 - accuracy: 0.3472\n",
      "Epoch 00079: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3338 - accuracy: 0.3479 - val_loss: 10.7020 - val_accuracy: 0.3505\n",
      "Epoch 80/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3204 - accuracy: 0.3522\n",
      "Epoch 00080: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3225 - accuracy: 0.3479 - val_loss: 14.1478 - val_accuracy: 0.3505\n",
      "Epoch 81/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3222 - accuracy: 0.3500\n",
      "Epoch 00081: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3248 - accuracy: 0.3479 - val_loss: 12.3905 - val_accuracy: 0.3505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3156 - accuracy: 0.3491\n",
      "Epoch 00082: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3196 - accuracy: 0.3479 - val_loss: 13.5527 - val_accuracy: 0.3505\n",
      "Epoch 83/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3162 - accuracy: 0.3495\n",
      "Epoch 00083: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3176 - accuracy: 0.3479 - val_loss: 17.9900 - val_accuracy: 0.3505\n",
      "Epoch 84/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3189 - accuracy: 0.3500\n",
      "Epoch 00084: val_loss did not improve from 1.35993\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3203 - accuracy: 0.3479 - val_loss: 15.3502 - val_accuracy: 0.3505\n",
      "Epoch 00084: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history_inceptionv3_fe_drop_128 = inceptionv3_fe_drop_128.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=200,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[checkpoint, earlystopping],\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "models.save_model(inceptionv3_fe_drop_128, 'inceptionv3_fe_drop_128_4cl_end.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# History of accuracy and loss\n",
    "tra_loss_fe = history_inceptionv3_fe_drop_128.history['loss']\n",
    "tra_acc_fe = history_inceptionv3_fe_drop_128.history['accuracy']\n",
    "val_loss_fe = history_inceptionv3_fe_drop_128.history['val_loss']\n",
    "val_acc_fe = history_inceptionv3_fe_drop_128.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of epochs training\n",
    "epochs_fe = range(1, len(tra_acc_fe)+1)\n",
    "end_epoch_fe = len(tra_acc_fe)\n",
    "\n",
    "# Epoch when reached the validation loss minimum\n",
    "opt_epoch_fe = val_loss_fe.index(min(val_loss_fe)) + 1\n",
    "\n",
    "# Loss and accuracy on the validation set\n",
    "end_val_loss_fe = val_loss_fe[-1]\n",
    "end_val_acc_fe = val_acc_fe[-1]\n",
    "opt_val_loss_fe = val_loss_fe[opt_epoch_fe-1]\n",
    "opt_val_acc_fe = val_acc_fe[opt_epoch_fe-1]\n",
    "\n",
    "# Loss and accuracy on the test set\n",
    "opt_inceptionv3_fe_drop_128 = models.load_model('inceptionv3_fe_drop_128_4cl_best.h5')\n",
    "test_loss_fe, test_acc_fe = inceptionv3_fe_drop_128.evaluate(test_images, test_labels, verbose=False)\n",
    "opt_test_loss_fe, opt_test_acc_fe = opt_inceptionv3_fe_drop_128.evaluate(test_images, test_labels, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inceptionv3 (w/ dropout, smaller FC) Feature Extraction\n",
      "\n",
      "Epoch [end]: 84\n",
      "Epoch [opt]: 54\n",
      "Valid accuracy [end]: 0.3505\n",
      "Valid accuracy [opt]: 0.3522\n",
      "Test accuracy [end]:  0.3176\n",
      "Test accuracy [opt]:  0.3145\n",
      "Valid loss [end]: 15.3502\n",
      "Valid loss [opt]: 1.3599\n",
      "Test loss [end]:  14.1136\n",
      "Test loss [opt]:  1.3790\n"
     ]
    }
   ],
   "source": [
    "print(\"inceptionv3 (w/ dropout, smaller FC) Feature Extraction\\n\")\n",
    "\n",
    "print(\"Epoch [end]: %d\" % end_epoch_fe)\n",
    "print(\"Epoch [opt]: %d\" % opt_epoch_fe)\n",
    "print(\"Valid accuracy [end]: %.4f\" % end_val_acc_fe)\n",
    "print(\"Valid accuracy [opt]: %.4f\" % opt_val_acc_fe)\n",
    "print(\"Test accuracy [end]:  %.4f\" % test_acc_fe)\n",
    "print(\"Test accuracy [opt]:  %.4f\" % opt_test_acc_fe)\n",
    "print(\"Valid loss [end]: %.4f\" % end_val_loss_fe)\n",
    "print(\"Valid loss [opt]: %.4f\" % opt_val_loss_fe)\n",
    "print(\"Test loss [end]:  %.4f\" % test_loss_fe)\n",
    "print(\"Test loss [opt]:  %.4f\" % opt_test_loss_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 560x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 560x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model accuracy\n",
    "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.title('inceptionv3 w/ dropout FC 128 FE accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs_fe, tra_acc_fe, 'r', label='Training set')\n",
    "plt.plot(epochs_fe, val_acc_fe, 'g', label='Validation set')\n",
    "plt.plot(opt_epoch_fe, val_acc_fe[opt_epoch_fe-1], 'go')\n",
    "plt.vlines(opt_epoch_fe, min(val_acc_fe), opt_val_acc_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.hlines(opt_val_acc_fe, 1, opt_epoch_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Model loss\n",
    "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.title('inceptionv3 w/ dropout FC 128 FE loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs_fe, tra_loss_fe, 'r', label='Training set')\n",
    "plt.plot(epochs_fe, val_loss_fe, 'g', label='Validation set')\n",
    "plt.plot(opt_epoch_fe, val_loss_fe[opt_epoch_fe-1], 'go')\n",
    "plt.vlines(opt_epoch_fe, min(val_loss_fe), opt_val_loss_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.hlines(opt_val_loss_fe, 1, opt_epoch_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
