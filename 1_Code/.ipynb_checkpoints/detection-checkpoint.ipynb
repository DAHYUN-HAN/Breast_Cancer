{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (350, 350)\n",
    "PYR_SCALE = 1.5\n",
    "WIN_STEP = 16\n",
    "ROI_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, step, ws):\n",
    "\t# slide a window across the image\n",
    "\tfor y in range(0, image.shape[0] - ws[1], step):\n",
    "\t\tfor x in range(0, image.shape[1] - ws[0], step):\n",
    "\t\t\t# yield the current window\n",
    "\t\t\tyield (x, y, image[y:y + ws[1], x:x + ws[0]])\n",
    "\n",
    "def image_pyramid(image, scale=1.5, minSize=(224, 224)):\n",
    "\t# yield the original image\n",
    "\tyield image\n",
    "\n",
    "\t# keep looping over the image pyramid\n",
    "\twhile True:\n",
    "\t\t# compute the dimensions of the next image in the pyramid\n",
    "\t\tw = int(image.shape[1] / scale)\n",
    "\t\timage = imutils.resize(image, width=w)\n",
    "\n",
    "\t\t# if the resized image does not meet the supplied minimum\n",
    "\t\t# size, then stop constructing the pyramid\n",
    "\t\tif image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# yield the next image in the pyramid\n",
    "\t\tyield image\n",
    "\n",
    "def classify_batch(model, batchROIs, batchLocs, labels, minProb=0.5,\n",
    "\ttop=10, dims=(224, 224)):\n",
    "\t# pass our batch ROIs through our network and decode the\n",
    "\t# predictions\n",
    "\tpreds = model.predict(batchROIs)\n",
    "\tP = imagenet_utils.decode_predictions(preds, top=top)\n",
    "\n",
    "\t# loop over the decoded predictions\n",
    "\tfor i in range(0, len(P)):\n",
    "\t\tfor (_, label, prob) in P[i]:\n",
    "\t\t\t# filter out weak detections by ensuring the\n",
    "\t\t\t# predicted probability is greater than the minimum\n",
    "\t\t\t# probability\n",
    "\t\t\tif prob > minProb:\n",
    "\t\t\t\t# grab the coordinates of the sliding window for\n",
    "\t\t\t\t# the prediction and construct the bounding box\n",
    "\t\t\t\t(pX, pY) = batchLocs[i]\n",
    "\t\t\t\tbox = (pX, pY, pX + dims[0], pY + dims[1])\n",
    "\n",
    "\t\t\t\t# grab the list of predictions for the label and\n",
    "\t\t\t\t# add the bounding box + probability to the list\n",
    "\t\t\t\tL = labels.get(label, [])\n",
    "\t\t\t\tL.append((box, prob))\n",
    "\t\t\t\tlabels[label] = L\n",
    "\n",
    "\t# return the labels dictionary\n",
    "\treturn labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    }
   ],
   "source": [
    "# load our the network weights from disk\n",
    "print(\"[INFO] loading network...\")\n",
    "model = VGG16(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "# initialize the object detection dictionary which maps class labels\n",
    "# to their predicted bounding boxes and associated probability\n",
    "labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image from disk and grab its dimensions\n",
    "orig = cv2.imread(\"../mass1.png\")\n",
    "(h, w) = orig.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the input image to be a square\n",
    "resized = cv2.resize(orig, INPUT_SIZE, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# initialize the batch ROIs and (x, y)-coordinates\n",
    "batchROIs = None\n",
    "batchLocs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] detecting objects...\n"
     ]
    }
   ],
   "source": [
    "# start the timer\n",
    "print(\"[INFO] detecting objects...\")\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imutils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-5255fd8be64a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# loop over the image pyramid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m for image in image_pyramid(resized, scale=PYR_SCALE,\n\u001b[1;32m----> 3\u001b[1;33m \tminSize=ROI_SIZE):\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;31m# loop over the sliding window locations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWIN_STEP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROI_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-68ac8786b467>\u001b[0m in \u001b[0;36mimage_pyramid\u001b[1;34m(image, scale, minSize)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;31m# compute the dimensions of the next image in the pyramid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[1;31m# if the resized image does not meet the supplied minimum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imutils' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# loop over the image pyramid\n",
    "for image in image_pyramid(resized, scale=PYR_SCALE,\n",
    "\tminSize=ROI_SIZE):\n",
    "\t# loop over the sliding window locations\n",
    "\tfor (x, y, roi) in sliding_window(resized, WIN_STEP, ROI_SIZE):\n",
    "\t\t# take the ROI and pre-process it so we can later classify the\n",
    "\t\t# region with Keras\n",
    "\t\troi = img_to_array(roi)\n",
    "\t\troi = np.expand_dims(roi, axis=0)\n",
    "\t\troi = imagenet_utils.preprocess_input(roi)\n",
    "\n",
    "\t\t# if the batch is None, initialize it\n",
    "\t\tif batchROIs is None:\n",
    "\t\t\tbatchROIs = roi\n",
    "\n",
    "\t\t# otherwise, add the ROI to the bottom of the batch\n",
    "\t\telse:\n",
    "\t\t\tbatchROIs = np.vstack([batchROIs, roi])\n",
    "\n",
    "\t\t# add the (x, y)-coordinates of the sliding window to the batch\n",
    "\t\tbatchLocs.append((x, y))\n",
    "\n",
    "\t\t# check to see if our batch is full\n",
    "\t\tif len(batchROIs) == BATCH_SIZE:\n",
    "\t\t\t# classify the batch, then reset the batch ROIs and\n",
    "\t\t\t# (x, y)-coordinates\n",
    "\t\t\tlabels = classify_batch(model, batchROIs, batchLocs,\n",
    "\t\t\t\tlabels)\n",
    "\n",
    "\t\t\t# reset the batch ROIs and (x, y)-coordinates\n",
    "\t\t\tbatchROIs = None\n",
    "\t\t\tbatchLocs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c7841c4a3266>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbatchROIs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \tlabels = classify_batch(model, batchROIs, batchLocs, labels,\n\u001b[1;32m----> 5\u001b[1;33m \t\tminProb=args[\"confidence\"])\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "# check to see if there are any remaining ROIs that still need to be\n",
    "# classified\n",
    "if batchROIs is not None:\n",
    "\tlabels = classify_batch(model, batchROIs, batchLocs, labels,\n",
    "\t\tminProb=args[\"confidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] detections took 132.8531 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# show how long the detection process took\n",
    "end = time.time()\n",
    "print(\"[INFO] detections took {:.4f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the labels for each of detected objects in the image\n",
    "for k in labels.keys():\n",
    "  # clone the input image so we can draw on it\n",
    "\tclone = resized.copy()\n",
    "\n",
    "\t# loop over all bounding boxes for the label and draw them on\n",
    "\t# the image\n",
    "\tfor (box, prob) in labels[k]:\n",
    "\t\t(xA, yA, xB, yB) = box\n",
    "\t\tcv2.rectangle(clone, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "\n",
    "\t# show the image *without* apply non-maxima suppression\n",
    "\tcv2.imshow(\"Without NMS\", clone)\n",
    "\tclone = resized.copy()\n",
    "\n",
    "\t# grab the bounding boxes and associated probabilities for each\n",
    "\t# detection, then apply non-maxima suppression to suppress\n",
    "\t# weaker, overlapping detections\n",
    "\tboxes = np.array([p[0] for p in labels[k]])\n",
    "\tproba = np.array([p[1] for p in labels[k]])\n",
    "\tboxes = non_max_suppression(boxes, proba)\n",
    "\n",
    "\t# loop over the bounding boxes again, this time only drawing the\n",
    "\t# ones that were *not* suppressed\n",
    "\tfor (xA, yA, xB, yB) in boxes:\n",
    "\t\tcv2.rectangle(clone, (xA, yA), (xB, yB), (0, 0, 255), 2)\n",
    "\n",
    "\t# show the output image\n",
    "\tprint(\"[INFO] {}: {}\".format(k, len(boxes)))\n",
    "\tcv2.imshow(\"With NMS\", clone)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
