{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "#from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adadelta, Adagrad, Adamax, Nadam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization, GlobalAveragePooling2D  \n",
    "from tensorflow.keras.backend import batch_normalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from packaging import version\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not tf.test.is_gpu_available():\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training():\n",
    "    \"\"\"\n",
    "    Load the training set (excluding baseline patches)\n",
    "    \"\"\"\n",
    "    images = np.load(os.path.join('Data_new3', 'X_train.npy'))\n",
    "    labels = np.load(os.path.join('Data_new3', 'train_labels_multi.npy'))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_testing():\n",
    "    \"\"\"\n",
    "    Load the test set (abnormalities patches and labels, no baseline)\n",
    "    \"\"\"\n",
    "    images = np.load(os.path.join('Data_new3', 'X_test.npy'))\n",
    "    labels = np.load(os.path.join('Data_new3', 'y_test_labels_multi.npy'))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def remap_label(l):\n",
    "    \"\"\"\n",
    "    Remap the labels to:\n",
    "        0 -> mass benign \n",
    "        1 -> mass malignant\n",
    "        2 -> calcification benign\n",
    "        3 -> calcification malignant\n",
    "    \"\"\"\n",
    "    if 1 <= l <= 4:\n",
    "        return l-1\n",
    "    else:\n",
    "        print(\"[WARN] Unrecognized label (%d)\" % l)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2913 \t Test size: 655\n",
      "Image size: 256x256\n"
     ]
    }
   ],
   "source": [
    "# Load training and test images (abnormalities only, no baseline)\n",
    "train_images, train_labels= load_training()\n",
    "test_images, test_labels= load_testing()\n",
    "\n",
    "# Number of images\n",
    "n_train_img = train_images.shape[0]\n",
    "n_test_img = test_images.shape[0]\n",
    "print(\"Train size: %d \\t Test size: %d\" % (n_train_img, n_test_img))\n",
    "\n",
    "# Compute width and height of images\n",
    "img_w = train_images.shape[1]\n",
    "img_h = train_images.shape[2]\n",
    "print(\"Image size: %dx%d\" % (img_w, img_h))\n",
    "\n",
    "# Convert the labels to categorical format\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels_raw = test_labels.copy()\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Create a new dimension for color in the images arrays\n",
    "train_images = train_images.reshape((n_train_img, img_w, img_h, 1))\n",
    "test_images = test_images.reshape((n_test_img, img_w, img_h, 1))\n",
    "\n",
    "# Convert from 16-bit (0-65535) to to 8-bit (0-255)\n",
    "train_images = train_images.astype('uint16') / 255\n",
    "test_images = test_images.astype('uint16') / 255\n",
    "\n",
    "# Replicate the only color channel (gray) 3 times, for VGGNet compatibility\n",
    "train_images = np.repeat(train_images, 3, axis=3)\n",
    "test_images = np.repeat(test_images, 3, axis=3)\n",
    "\n",
    "# Shuffle the training set (originally sorted by label)\n",
    "perm = np.random.permutation(n_train_img)\n",
    "train_images = train_images[perm]\n",
    "train_labels = train_labels[perm]\n",
    "\n",
    "# Create a generator for training images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=180,\n",
    "    shear_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# Fit the generator with some images\n",
    "train_datagen.fit(train_images)\n",
    "\n",
    "# Split train images into actual training and validation\n",
    "train_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='training')\n",
    "validation_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='validation')\n",
    "\n",
    "# Preprocess the test images as well\n",
    "preprocess_input(test_images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using VGG16 convolutional base and new FC final layer\n",
    "\n",
    "def create_resnet50(verbose=False, fc_size=256, dropout=None):\n",
    "    \n",
    "    from tensorflow.keras.applications import resnet50\n",
    "    \n",
    "    resnet50_base = resnet50.ResNet50(weights='imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(256, 256, 3))\n",
    "    resnet50 = models.Sequential()\n",
    "    resnet50.add(resnet50_base)\n",
    "\n",
    "    resnet50.add(layers.Flatten())\n",
    "    if dropout is not None:\n",
    "        resnet50.add(layers.Dropout(dropout))\n",
    "    resnet50.add(layers.Dense(fc_size, activation='relu'))\n",
    "    resnet50.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "    # Freeze the convolutional base\n",
    "    resnet50_base.trainable = False\n",
    "    \n",
    "    if verbose:\n",
    "        resnet50_base.summary()\n",
    "        resnet50.summary()\n",
    "\n",
    "    return resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               33554688  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 57,143,428\n",
      "Trainable params: 33,555,716\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50_fe_drop_temp = create_resnet50(verbose=True, dropout=0.5, fc_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_base = resnet50.ResNet50(weights='imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a VGG19 network with custom final layer\n",
    "resnet50 = models.Sequential()\n",
    "resnet50.add(resnet50_base)\n",
    "resnet50.add(layers.Flatten())\n",
    "\n",
    "resnet50.add(layers.Dropout(0.5))\n",
    "resnet50.add(layers.Dense(128, activation='relu'))\n",
    "resnet50.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "resnet50_base.trainable = False\n",
    "\n",
    "resnet50_fe_drop_128 = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16777344  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 40,365,572\n",
      "Trainable params: 16,777,860\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50_fe_drop_128.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping (stop training after the validation loss reaches the minimum)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=30, verbose=1)\n",
    "\n",
    "# Callback for checkpointing\n",
    "checkpoint = ModelCheckpoint('resnet50_fe_drop_128_4cl_best.h5', \n",
    "        monitor='val_loss', mode='min', verbose=1, \n",
    "        save_best_only=True, save_freq='epoch'\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "resnet50_fe_drop_128.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-f5d72695d460>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 19 steps, validate for 5 steps\n",
      "Epoch 1/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 23.0123 - accuracy: 0.3227\n",
      "Epoch 00001: val_loss improved from inf to 1.38391, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 33s 2s/step - loss: 21.5278 - accuracy: 0.3235 - val_loss: 1.3839 - val_accuracy: 0.3540\n",
      "Epoch 2/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3961 - accuracy: 0.3445\n",
      "Epoch 00002: val_loss improved from 1.38391 to 1.38270, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3955 - accuracy: 0.3436 - val_loss: 1.3827 - val_accuracy: 0.3574\n",
      "Epoch 3/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3942 - accuracy: 0.3463\n",
      "Epoch 00003: val_loss improved from 1.38270 to 1.38006, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3942 - accuracy: 0.3453 - val_loss: 1.3801 - val_accuracy: 0.3574\n",
      "Epoch 4/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3797 - accuracy: 0.3454\n",
      "Epoch 00004: val_loss improved from 1.38006 to 1.37726, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3796 - accuracy: 0.3462 - val_loss: 1.3773 - val_accuracy: 0.3574\n",
      "Epoch 5/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3858 - accuracy: 0.3386\n",
      "Epoch 00005: val_loss improved from 1.37726 to 1.37390, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3847 - accuracy: 0.3441 - val_loss: 1.3739 - val_accuracy: 0.3574\n",
      "Epoch 6/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3762 - accuracy: 0.3409\n",
      "Epoch 00006: val_loss improved from 1.37390 to 1.37060, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3754 - accuracy: 0.3462 - val_loss: 1.3706 - val_accuracy: 0.3574\n",
      "Epoch 7/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3742 - accuracy: 0.3459\n",
      "Epoch 00007: val_loss improved from 1.37060 to 1.36923, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3740 - accuracy: 0.3462 - val_loss: 1.3692 - val_accuracy: 0.3574\n",
      "Epoch 8/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3773 - accuracy: 0.3450\n",
      "Epoch 00008: val_loss improved from 1.36923 to 1.36775, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3764 - accuracy: 0.3458 - val_loss: 1.3678 - val_accuracy: 0.3574\n",
      "Epoch 9/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3670 - accuracy: 0.3500\n",
      "Epoch 00009: val_loss improved from 1.36775 to 1.36487, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3676 - accuracy: 0.3462 - val_loss: 1.3649 - val_accuracy: 0.3574\n",
      "Epoch 10/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3643 - accuracy: 0.3500\n",
      "Epoch 00010: val_loss did not improve from 1.36487\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3658 - accuracy: 0.3462 - val_loss: 1.3650 - val_accuracy: 0.3574\n",
      "Epoch 11/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3683 - accuracy: 0.3482\n",
      "Epoch 00011: val_loss improved from 1.36487 to 1.36301, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3688 - accuracy: 0.3462 - val_loss: 1.3630 - val_accuracy: 0.3574\n",
      "Epoch 12/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3663 - accuracy: 0.3404\n",
      "Epoch 00012: val_loss did not improve from 1.36301\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3619 - accuracy: 0.3458 - val_loss: 1.3655 - val_accuracy: 0.3574\n",
      "Epoch 13/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3651 - accuracy: 0.3436\n",
      "Epoch 00013: val_loss improved from 1.36301 to 1.34993, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3614 - accuracy: 0.3458 - val_loss: 1.3499 - val_accuracy: 0.3574\n",
      "Epoch 14/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3541 - accuracy: 0.3468\n",
      "Epoch 00014: val_loss improved from 1.34993 to 1.33231, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3519 - accuracy: 0.3462 - val_loss: 1.3323 - val_accuracy: 0.3574\n",
      "Epoch 15/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3643 - accuracy: 0.3500\n",
      "Epoch 00015: val_loss did not improve from 1.33231\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3657 - accuracy: 0.3462 - val_loss: 1.3587 - val_accuracy: 0.3574\n",
      "Epoch 16/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3631 - accuracy: 0.3459\n",
      "Epoch 00016: val_loss did not improve from 1.33231\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3612 - accuracy: 0.3462 - val_loss: 1.3400 - val_accuracy: 0.3574\n",
      "Epoch 17/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3471 - accuracy: 0.3473\n",
      "Epoch 00017: val_loss did not improve from 1.33231\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3459 - accuracy: 0.3462 - val_loss: 1.3452 - val_accuracy: 0.3574\n",
      "Epoch 18/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3568 - accuracy: 0.3409\n",
      "Epoch 00018: val_loss improved from 1.33231 to 1.33121, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3519 - accuracy: 0.3462 - val_loss: 1.3312 - val_accuracy: 0.3574\n",
      "Epoch 19/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3456 - accuracy: 0.3463\n",
      "Epoch 00019: val_loss did not improve from 1.33121\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3463 - accuracy: 0.3462 - val_loss: 1.3439 - val_accuracy: 0.3574\n",
      "Epoch 20/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3389 - accuracy: 0.3409\n",
      "Epoch 00020: val_loss did not improve from 1.33121\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3365 - accuracy: 0.3462 - val_loss: 1.3409 - val_accuracy: 0.3574\n",
      "Epoch 21/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3296 - accuracy: 0.3473\n",
      "Epoch 00021: val_loss did not improve from 1.33121\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3291 - accuracy: 0.3462 - val_loss: 1.3437 - val_accuracy: 0.3574\n",
      "Epoch 22/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3166 - accuracy: 0.3500\n",
      "Epoch 00022: val_loss did not improve from 1.33121\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3216 - accuracy: 0.3462 - val_loss: 1.3448 - val_accuracy: 0.3574\n",
      "Epoch 23/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3228 - accuracy: 0.3468\n",
      "Epoch 00023: val_loss did not improve from 1.33121\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3182 - accuracy: 0.3462 - val_loss: 1.3332 - val_accuracy: 0.3574\n",
      "Epoch 24/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3229 - accuracy: 0.3473\n",
      "Epoch 00024: val_loss did not improve from 1.33121\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3205 - accuracy: 0.3466 - val_loss: 1.3345 - val_accuracy: 0.3574\n",
      "Epoch 25/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3347 - accuracy: 0.3463\n",
      "Epoch 00025: val_loss did not improve from 1.33121\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3333 - accuracy: 0.3462 - val_loss: 1.3438 - val_accuracy: 0.3574\n",
      "Epoch 26/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3080 - accuracy: 0.3463\n",
      "Epoch 00026: val_loss did not improve from 1.33121\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3087 - accuracy: 0.3462 - val_loss: 1.3441 - val_accuracy: 0.3574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3080 - accuracy: 0.3468\n",
      "Epoch 00027: val_loss improved from 1.33121 to 1.31826, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3052 - accuracy: 0.3462 - val_loss: 1.3183 - val_accuracy: 0.3574\n",
      "Epoch 28/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2948 - accuracy: 0.3491\n",
      "Epoch 00028: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2965 - accuracy: 0.3462 - val_loss: 1.3327 - val_accuracy: 0.3574\n",
      "Epoch 29/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3026 - accuracy: 0.3473\n",
      "Epoch 00029: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.3042 - accuracy: 0.3462 - val_loss: 1.3380 - val_accuracy: 0.3574\n",
      "Epoch 30/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2980 - accuracy: 0.3468\n",
      "Epoch 00030: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2954 - accuracy: 0.3462 - val_loss: 1.3298 - val_accuracy: 0.3574\n",
      "Epoch 31/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2897 - accuracy: 0.3409\n",
      "Epoch 00031: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2857 - accuracy: 0.3462 - val_loss: 1.3364 - val_accuracy: 0.3574\n",
      "Epoch 32/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.3026 - accuracy: 0.3482\n",
      "Epoch 00032: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.3017 - accuracy: 0.3462 - val_loss: 1.3349 - val_accuracy: 0.3574\n",
      "Epoch 33/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2907 - accuracy: 0.3473\n",
      "Epoch 00033: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2906 - accuracy: 0.3462 - val_loss: 1.3302 - val_accuracy: 0.3574\n",
      "Epoch 34/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2925 - accuracy: 0.3459\n",
      "Epoch 00034: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2923 - accuracy: 0.3462 - val_loss: 1.3388 - val_accuracy: 0.3574\n",
      "Epoch 35/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2914 - accuracy: 0.3586\n",
      "Epoch 00035: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2874 - accuracy: 0.3634 - val_loss: 1.3229 - val_accuracy: 0.3711\n",
      "Epoch 36/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2763 - accuracy: 0.3945\n",
      "Epoch 00036: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2732 - accuracy: 0.3998 - val_loss: 1.3256 - val_accuracy: 0.3557\n",
      "Epoch 37/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2888 - accuracy: 0.4122\n",
      "Epoch 00037: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2934 - accuracy: 0.4058 - val_loss: 1.3500 - val_accuracy: 0.3522\n",
      "Epoch 38/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.4284 - accuracy: 0.4013\n",
      "Epoch 00038: val_loss did not improve from 1.31826\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.4261 - accuracy: 0.3968 - val_loss: 1.3490 - val_accuracy: 0.3368\n",
      "Epoch 39/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2807 - accuracy: 0.3963\n",
      "Epoch 00039: val_loss improved from 1.31826 to 1.31611, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.2756 - accuracy: 0.4015 - val_loss: 1.3161 - val_accuracy: 0.3918\n",
      "Epoch 40/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2767 - accuracy: 0.4031\n",
      "Epoch 00040: val_loss did not improve from 1.31611\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.2783 - accuracy: 0.4003 - val_loss: 1.3433 - val_accuracy: 0.3368\n",
      "Epoch 41/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2703 - accuracy: 0.3990\n",
      "Epoch 00041: val_loss improved from 1.31611 to 1.30946, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.2668 - accuracy: 0.4020 - val_loss: 1.3095 - val_accuracy: 0.3935\n",
      "Epoch 42/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2660 - accuracy: 0.4072\n",
      "Epoch 00042: val_loss did not improve from 1.30946\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2667 - accuracy: 0.4058 - val_loss: 1.3312 - val_accuracy: 0.3660\n",
      "Epoch 43/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2574 - accuracy: 0.4122\n",
      "Epoch 00043: val_loss did not improve from 1.30946\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2598 - accuracy: 0.4101 - val_loss: 1.3284 - val_accuracy: 0.3832\n",
      "Epoch 44/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2830 - accuracy: 0.3954\n",
      "Epoch 00044: val_loss did not improve from 1.30946\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2804 - accuracy: 0.3955 - val_loss: 1.3191 - val_accuracy: 0.3935\n",
      "Epoch 45/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2652 - accuracy: 0.4094\n",
      "Epoch 00045: val_loss did not improve from 1.30946\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2672 - accuracy: 0.4084 - val_loss: 1.3228 - val_accuracy: 0.3918\n",
      "Epoch 46/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2394 - accuracy: 0.4144\n",
      "Epoch 00046: val_loss did not improve from 1.30946\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2405 - accuracy: 0.4157 - val_loss: 1.3098 - val_accuracy: 0.4141\n",
      "Epoch 47/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2552 - accuracy: 0.4122\n",
      "Epoch 00047: val_loss improved from 1.30946 to 1.30815, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.2497 - accuracy: 0.4174 - val_loss: 1.3082 - val_accuracy: 0.4089\n",
      "Epoch 48/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2527 - accuracy: 0.3995\n",
      "Epoch 00048: val_loss improved from 1.30815 to 1.29805, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.2484 - accuracy: 0.4041 - val_loss: 1.2981 - val_accuracy: 0.4021\n",
      "Epoch 49/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2631 - accuracy: 0.4108\n",
      "Epoch 00049: val_loss did not improve from 1.29805\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2627 - accuracy: 0.4088 - val_loss: 1.3207 - val_accuracy: 0.3797\n",
      "Epoch 50/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2533 - accuracy: 0.4194\n",
      "Epoch 00050: val_loss did not improve from 1.29805\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2505 - accuracy: 0.4226 - val_loss: 1.2985 - val_accuracy: 0.4261\n",
      "Epoch 51/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2513 - accuracy: 0.4049\n",
      "Epoch 00051: val_loss did not improve from 1.29805\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2507 - accuracy: 0.4058 - val_loss: 1.3024 - val_accuracy: 0.4124\n",
      "Epoch 52/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2511 - accuracy: 0.4144\n",
      "Epoch 00052: val_loss did not improve from 1.29805\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2521 - accuracy: 0.4148 - val_loss: 1.3176 - val_accuracy: 0.4210\n",
      "Epoch 53/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2598 - accuracy: 0.4190\n",
      "Epoch 00053: val_loss improved from 1.29805 to 1.29652, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.2621 - accuracy: 0.4170 - val_loss: 1.2965 - val_accuracy: 0.3866\n",
      "Epoch 54/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2461 - accuracy: 0.4203\n",
      "Epoch 00054: val_loss did not improve from 1.29652\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2458 - accuracy: 0.4217 - val_loss: 1.3092 - val_accuracy: 0.4124\n",
      "Epoch 55/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2418 - accuracy: 0.4303\n",
      "Epoch 00055: val_loss did not improve from 1.29652\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2423 - accuracy: 0.4294 - val_loss: 1.3187 - val_accuracy: 0.3608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2434 - accuracy: 0.4308\n",
      "Epoch 00056: val_loss did not improve from 1.29652\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2387 - accuracy: 0.4350 - val_loss: 1.3109 - val_accuracy: 0.3986\n",
      "Epoch 57/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2495 - accuracy: 0.4244\n",
      "Epoch 00057: val_loss improved from 1.29652 to 1.29195, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.2451 - accuracy: 0.4294 - val_loss: 1.2920 - val_accuracy: 0.4124\n",
      "Epoch 58/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2326 - accuracy: 0.4448\n",
      "Epoch 00058: val_loss did not improve from 1.29195\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2364 - accuracy: 0.4389 - val_loss: 1.3185 - val_accuracy: 0.3677\n",
      "Epoch 59/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2428 - accuracy: 0.4384\n",
      "Epoch 00059: val_loss did not improve from 1.29195\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2472 - accuracy: 0.4384 - val_loss: 1.3034 - val_accuracy: 0.3729\n",
      "Epoch 60/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2339 - accuracy: 0.4467\n",
      "Epoch 00060: val_loss did not improve from 1.29195\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2387 - accuracy: 0.4436 - val_loss: 1.3069 - val_accuracy: 0.3574\n",
      "Epoch 61/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2436 - accuracy: 0.4380\n",
      "Epoch 00061: val_loss improved from 1.29195 to 1.28642, saving model to resnet50_fe_drop_128_4cl_best.h5\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.2347 - accuracy: 0.4444 - val_loss: 1.2864 - val_accuracy: 0.4107\n",
      "Epoch 62/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2469 - accuracy: 0.4462\n",
      "Epoch 00062: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2454 - accuracy: 0.4449 - val_loss: 1.3180 - val_accuracy: 0.3694\n",
      "Epoch 63/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2494 - accuracy: 0.4371\n",
      "Epoch 00063: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2492 - accuracy: 0.4380 - val_loss: 1.3078 - val_accuracy: 0.3677\n",
      "Epoch 64/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2373 - accuracy: 0.4571\n",
      "Epoch 00064: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2367 - accuracy: 0.4556 - val_loss: 1.2978 - val_accuracy: 0.3711\n",
      "Epoch 65/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2359 - accuracy: 0.4439\n",
      "Epoch 00065: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2311 - accuracy: 0.4474 - val_loss: 1.3027 - val_accuracy: 0.4158\n",
      "Epoch 66/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2422 - accuracy: 0.4344\n",
      "Epoch 00066: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2426 - accuracy: 0.4350 - val_loss: 1.3184 - val_accuracy: 0.3540\n",
      "Epoch 67/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2350 - accuracy: 0.4430\n",
      "Epoch 00067: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2342 - accuracy: 0.4427 - val_loss: 1.3129 - val_accuracy: 0.3557\n",
      "Epoch 68/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2304 - accuracy: 0.4367\n",
      "Epoch 00068: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2340 - accuracy: 0.4359 - val_loss: 1.3254 - val_accuracy: 0.3505\n",
      "Epoch 69/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2343 - accuracy: 0.4430\n",
      "Epoch 00069: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2332 - accuracy: 0.4423 - val_loss: 1.3222 - val_accuracy: 0.3643\n",
      "Epoch 70/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2448 - accuracy: 0.4349\n",
      "Epoch 00070: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2422 - accuracy: 0.4384 - val_loss: 1.3201 - val_accuracy: 0.3540\n",
      "Epoch 71/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2316 - accuracy: 0.4431\n",
      "Epoch 00071: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2433 - accuracy: 0.4427 - val_loss: 1.3235 - val_accuracy: 0.3625\n",
      "Epoch 72/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2316 - accuracy: 0.4358\n",
      "Epoch 00072: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2329 - accuracy: 0.4346 - val_loss: 1.3157 - val_accuracy: 0.3832\n",
      "Epoch 73/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2200 - accuracy: 0.4489\n",
      "Epoch 00073: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2186 - accuracy: 0.4522 - val_loss: 1.3114 - val_accuracy: 0.3574\n",
      "Epoch 74/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2192 - accuracy: 0.4680\n",
      "Epoch 00074: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2229 - accuracy: 0.4655 - val_loss: 1.3244 - val_accuracy: 0.3540\n",
      "Epoch 75/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2305 - accuracy: 0.4489\n",
      "Epoch 00075: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2321 - accuracy: 0.4470 - val_loss: 1.3008 - val_accuracy: 0.3488\n",
      "Epoch 76/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2322 - accuracy: 0.4512\n",
      "Epoch 00076: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2356 - accuracy: 0.4474 - val_loss: 1.3047 - val_accuracy: 0.3660\n",
      "Epoch 77/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2297 - accuracy: 0.4462\n",
      "Epoch 00077: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2318 - accuracy: 0.4432 - val_loss: 1.3342 - val_accuracy: 0.3522\n",
      "Epoch 78/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2284 - accuracy: 0.4512\n",
      "Epoch 00078: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2291 - accuracy: 0.4496 - val_loss: 1.3234 - val_accuracy: 0.3591\n",
      "Epoch 79/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2300 - accuracy: 0.4458\n",
      "Epoch 00079: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2284 - accuracy: 0.4457 - val_loss: 1.3095 - val_accuracy: 0.3574\n",
      "Epoch 80/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2256 - accuracy: 0.4571\n",
      "Epoch 00080: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2262 - accuracy: 0.4539 - val_loss: 1.3202 - val_accuracy: 0.3351\n",
      "Epoch 81/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2249 - accuracy: 0.4399\n",
      "Epoch 00081: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2216 - accuracy: 0.4440 - val_loss: 1.3113 - val_accuracy: 0.3557\n",
      "Epoch 82/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2291 - accuracy: 0.4389\n",
      "Epoch 00082: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2303 - accuracy: 0.4419 - val_loss: 1.3382 - val_accuracy: 0.3213\n",
      "Epoch 83/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2269 - accuracy: 0.4471\n",
      "Epoch 00083: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2232 - accuracy: 0.4487 - val_loss: 1.3276 - val_accuracy: 0.3436\n",
      "Epoch 84/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2172 - accuracy: 0.4539\n",
      "Epoch 00084: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2188 - accuracy: 0.4513 - val_loss: 1.3523 - val_accuracy: 0.3213\n",
      "Epoch 85/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2171 - accuracy: 0.4598\n",
      "Epoch 00085: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2162 - accuracy: 0.4607 - val_loss: 1.3475 - val_accuracy: 0.3488\n",
      "Epoch 86/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2140 - accuracy: 0.4367\n",
      "Epoch 00086: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2157 - accuracy: 0.4376 - val_loss: 1.3363 - val_accuracy: 0.3505\n",
      "Epoch 87/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2074 - accuracy: 0.4485\n",
      "Epoch 00087: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2101 - accuracy: 0.4470 - val_loss: 1.3230 - val_accuracy: 0.3729\n",
      "Epoch 88/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2074 - accuracy: 0.4553\n",
      "Epoch 00088: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2036 - accuracy: 0.4569 - val_loss: 1.3045 - val_accuracy: 0.3797\n",
      "Epoch 89/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2291 - accuracy: 0.4494\n",
      "Epoch 00089: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2291 - accuracy: 0.4487 - val_loss: 1.3140 - val_accuracy: 0.3471\n",
      "Epoch 90/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2130 - accuracy: 0.4635\n",
      "Epoch 00090: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 30s 2s/step - loss: 1.2119 - accuracy: 0.4650 - val_loss: 1.3364 - val_accuracy: 0.3488\n",
      "Epoch 91/200\n",
      "18/19 [===========================>..] - ETA: 1s - loss: 1.2214 - accuracy: 0.4439\n",
      "Epoch 00091: val_loss did not improve from 1.28642\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.2237 - accuracy: 0.4449 - val_loss: 1.3135 - val_accuracy: 0.3625\n",
      "Epoch 00091: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history_resnet50_fe_drop_128 = resnet50_fe_drop_128.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=200,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[checkpoint, earlystopping],\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "models.save_model(resnet50_fe_drop_128, 'resnet50_fe_drop_128_4cl_end.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# History of accuracy and loss\n",
    "tra_loss_fe = history_resnet50_fe_drop_128.history['loss']\n",
    "tra_acc_fe = history_resnet50_fe_drop_128.history['accuracy']\n",
    "val_loss_fe = history_resnet50_fe_drop_128.history['val_loss']\n",
    "val_acc_fe = history_resnet50_fe_drop_128.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of epochs training\n",
    "epochs_fe = range(1, len(tra_acc_fe)+1)\n",
    "end_epoch_fe = len(tra_acc_fe)\n",
    "\n",
    "# Epoch when reached the validation loss minimum\n",
    "opt_epoch_fe = val_loss_fe.index(min(val_loss_fe)) + 1\n",
    "\n",
    "# Loss and accuracy on the validation set\n",
    "end_val_loss_fe = val_loss_fe[-1]\n",
    "end_val_acc_fe = val_acc_fe[-1]\n",
    "opt_val_loss_fe = val_loss_fe[opt_epoch_fe-1]\n",
    "opt_val_acc_fe = val_acc_fe[opt_epoch_fe-1]\n",
    "\n",
    "# Loss and accuracy on the test set\n",
    "opt_resnet50_fe_drop_128 = models.load_model('resnet50_fe_drop_128_4cl_best.h5')\n",
    "test_loss_fe, test_acc_fe = resnet50_fe_drop_128.evaluate(test_images, test_labels, verbose=False)\n",
    "opt_test_loss_fe, opt_test_acc_fe = opt_resnet50_fe_drop_128.evaluate(test_images, test_labels, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 (w/ dropout, smaller FC) Feature Extraction\n",
      "\n",
      "Epoch [end]: 91\n",
      "Epoch [opt]: 61\n",
      "Valid accuracy [end]: 0.3625\n",
      "Valid accuracy [opt]: 0.4107\n",
      "Test accuracy [end]:  0.3939\n",
      "Test accuracy [opt]:  0.4382\n",
      "Valid loss [end]: 1.3135\n",
      "Valid loss [opt]: 1.2864\n",
      "Test loss [end]:  1.2436\n",
      "Test loss [opt]:  1.2458\n"
     ]
    }
   ],
   "source": [
    "print(\"resnet50 (w/ dropout, smaller FC) Feature Extraction\\n\")\n",
    "\n",
    "print(\"Epoch [end]: %d\" % end_epoch_fe)\n",
    "print(\"Epoch [opt]: %d\" % opt_epoch_fe)\n",
    "print(\"Valid accuracy [end]: %.4f\" % end_val_acc_fe)\n",
    "print(\"Valid accuracy [opt]: %.4f\" % opt_val_acc_fe)\n",
    "print(\"Test accuracy [end]:  %.4f\" % test_acc_fe)\n",
    "print(\"Test accuracy [opt]:  %.4f\" % opt_test_acc_fe)\n",
    "print(\"Valid loss [end]: %.4f\" % end_val_loss_fe)\n",
    "print(\"Valid loss [opt]: %.4f\" % opt_val_loss_fe)\n",
    "print(\"Test loss [end]:  %.4f\" % test_loss_fe)\n",
    "print(\"Test loss [opt]:  %.4f\" % opt_test_loss_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 560x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAHoCAYAAACcmUy/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXxU5cG38d+s2TdCQGBIgoQdFQoKImBRKkjRWqXVCq4o+ohaRVEf61O1LUWtRetCxWpx14q1rRSVVxRERBbBsBOWECDsEAJZZ73fP8YZMhIgLHEOcn0/n0PIzJkz95xM5pp7lozNGGMEAAAswR7vAQAAgAMIMwAAFkKYAQCwEMIMAICFEGYAACyEMAMAYCGEGQAACyHMgIU99NBD+vGPfxzvYeB7cP3112vEiBHxHgYsgDDjB2fGjBmy2WwHHf7jH/9YNpstZnn66adj1pk2bZo6d+6sxMRE9ejRQ/PmzTuhY6uurlZycrK2bt16QrdrBR6PR6+88sph13nllVcO+hnYbDatXr06us7SpUs1bNgw5eTkKDk5WV26dNFDDz2ksrKyere5bds2XXnllWrTpo1sNpteeumlmOP9fr/uu+8+denSRcnJycrNzdXdd9+tqqqqmPVefvllderUSUlJSWrTpo1+//vf63B/f6m+61Pv3r0lSbNmzar3cnbs2PGw+weQCDNOMK/XG+8hHNZdd92lbdu2RZdRo0ZFj1u9erUuv/xyXX311Vq8eLHOO+88DRkyRHv27Dlh5//pp5+qY8eOatmy5QnZntX3d31atGgR8zPYtm2b2rVrJ0n64osv1Lt3b6WlpWnatGlavXq1nn/+ea1bt06vv/56vdvzer1q2bKlxo0bp9NOO+2g46urq7V06VL97ne/05IlS/Tqq69q2rRpuuOOO6LrzJ49W7feeqvuu+8+rVq1Sn/5y1/0pz/9SS+//PJhL8t3r08ffvhhzPGlpaUxx8+ZM+dodxdORQY4Dueff7655557zE033WTS0tLM6NGjjTHGrF+/3gwdOtSkpKSYFi1amNGjR5uqqqro6Z566imTn59v3G63adWqlXn44Yejx0kykydPNhdeeKFJSkoyP/rRj8ySJUtizvftt982nTp1MomJiaZLly5mypQpxhhjNmzYYCTFLJMnT46O9Te/+c0hL8vdd99t+vTpE/0+FAqZ3Nxc89RTT9W7/p///GfTv3//6PePPPKIkWSKioqMMcZs377dSDJbt26NrjNq1Cjz0EMPHXIM7777rsnNzTXJycnm2muvNffcc485//zzo8cfan/Pnz/f9O7d27jdbuPxeMzjjz8es11J5sUXXzR9+/Y1CQkJpkePHmbp0qUx6zzxxBPG4/EYt9ttevXqZebPnx897uGHHzbnnXdezPrXXXedGT58eHRcdfd53THXNXnyZNOqVat6jwsGg6Zdu3bmF7/4Rb3H7927t97D68rLyzN/+9vfjrjeW2+9ZbKysqLfP/HEE+ass86KWefyyy83t9xyyyG3cbjr08yZM40k4/f7jziWiLr705jw9eeKK64wKSkpJjMz09x4442msrIy5jJ06NDBJCQkmObNm5ubb745etzhfr9gfcyYcdwmTZqktm3bavHixbrnnnvk8/k0aNAgtWvXTosWLdJ//vMfLVy4UPfcc48kaeHChXr44Yf1wgsvaO3atXr33XdVUFAQs83f/e53uuOOO1RYWKiWLVvqhhtuiB732Wef6Y477tCjjz6qFStW6MEHH9S1116refPmqXXr1nr33XclKTpLufLKK6OnffHFF9W0aVN169ZNf/7znxUMBqPHLViwQBdccEH0e5vNpgsuuEDz58+v93L369dPCxYsiM5av/jiC2VnZ+uLL76Ifl9QUKAWLVpET/Phhx9q6NCh9W5v/fr1uvrqq3XTTTdp8eLFKigo0KRJk464vysqKjRkyBB16dJFhYWFeuKJJ/Too4/qrbfeijndb3/7W915551avHix2rRpo5///OfRy//WW2/pkUce0WOPPabCwkKdeeaZGjJkiPbv31/vWL/r/fffV4sWLfT0009r27Ztev/99xt0uroKCwu1du3a6PXkuzIzM496m4eye/duNWnSJPp97969tWbNmuiMduXKlZo7d64uuuiiE3aeR+uaa67R5s2b9fnnn2vq1KmaPXu27r77bknh6/YNN9ygRx99VEVFRfrvf/+rHj16SGrY7xcsLt73DHByO//8882Pf/zjmMNeffVV06NHj5jDvvzyS+N2u00gEDDvvfeead++/SFnE5JiZnxz5841kkxFRYUxxpgBAwaYZ599NuY0N998sxk5cqQxxphPPvnE1HfV/tvf/mY+/fRTs3TpUvPiiy+arKysmNlru3btzDPPPBNzmrFjx5oLLrig3nH6/X6Tmppq5syZE/3/o48+aq699lpjjDF33HGHueGGG6Lrf/PNNyYnJ8cEg8F6t3ffffeZXr16xRzWq1evg2bM393ff/3rX03Lli1j9uf9999vevbsGf1ekrn//vuj35eXl5vk5GQzderU6PmMHTs25rJ5PB7z3HPPGWOOPGM2xphWrVpFH504lMmTJxubzWZSUlKiy+DBg40xxrzzzjtGUoNmxofSkBnznj17TF5enhk/fnzM4a+99ppJTEw0TqfT2Gw2M27cuMNu5/zzzzculyvmsrzxxhvGmAMz5rrHpaSkRK+j9am7P1etWmUkmRUrVkSP/+ijj4zT6TTl5eXm66+/Nunp6dHfibqO9PsF63PG8T4BfiC6d+8e8/2yZcu0ZMkSpaamRg8zxsjn82nLli0aOHCgfvOb36ht27a6+OKLdckll2jIkCExL9g644wzov+PPG+4c+dOpaamatmyZfrqq6/0wAMPRNfx+Xzq27fvYcd50003xWzf4XDo17/+tX73u9/JZrMd9oU+9XE6nerdu7e++OILOZ1O5eXl6ec//7l+9rOfSQrPmO+8887o+tOmTdOQIUNkt9f/QFVRUZHOOeecmMPOOeccLV26NOaw7+7voqIi9ejRQ07ngV/nc889VxMnTjxoWxEZGRnq0KGDioqKNHToUBUVFem+++6LuWw9e/ZUUVFRQ3bFUWnevHn0UQVJSkpKOuHncSjV1dX62c9+pq5du2rs2LHRw5cvX64HHnhATz31lM477zwtX75cv/71r3X66afrqquuOuT2br755ugsVgpftroWLVokh8MR/T4tLa1B4ywqKlJaWpo6d+4cPezcc89VIBDQ+vXrddZZZ+nMM8/U6aefriFDhmjIkCG67LLL5Ha7G/T7BWsjzDhuycnJMd9XVlaqf//+9T4M26JFC7lcLi1dulQzZszQxx9/rBtvvFG9evXSBx98EF3P5XJF/x+5QQmFQtHtP/nkkxo0aFDMto/2Br5Hjx6qrKzU7t27lZOTo+bNm2vnzp0x6+zatUvNmjU75Db69eunL774Qg6HQ/369VPXrl21b98+rVixQkuXLlW/fv2i6/73v//VmDFjDrktY0yDbjy/u78beofieG6Y7Xb7Qefj9/uPaZsOh6Peh1YjhxUVFalXr17HNtDDqK2t1SWXXCK326333nsvJpiPPfaYBg0apFtvvVVS+I7bhg0b9Kc//emwYc7Kyjrsw8Rt27aNucPUUPX9TOvua6fTqVmzZmn27Nn6+OOPdd999+mJJ57Q3LlzlZGRccTfL1gbzzHjhDvrrLO0evVqeTweFRQUxCyR4Lrdbg0ZMkTPPPOMpk6dqqlTpx4UxcNtv7i4+KBtt2rVStKBqNd9/rg+S5YsUUpKipo2bSopPKOcOXNmzDozZ848bCT69eunuXPn6vPPP1f//v1ls9l03nnnafz48WrWrFn0Rnv37t365ptvDrozUVeHDh20YMGCmMMWLlx42MsgSR07dtSiRYsUCASih3311VcHvTWn7rb379+vNWvWqEOHDtHzrvvWsEAgoK+//jq6jZycHG3fvj1me8uWLYv53uVyHXGfH0737t1VUFCgCRMm1Hv8vn37jnnbXq9Xl112maqrq/Wf//xHiYmJMcdXV1fHhFoK3xmJ3Bn8vnXs2FEVFRVauXJl9LC5c+fK6XSqbdu2ksJ3cAYMGKDHH39cCxYs0KJFi1RYWCjp+H6/EH+EGSfc8OHD5Xa7deWVV2rhwoVat26dpk6dqnvvvVdSeOb4/PPPa9myZSouLtY//vEPNW3aVNnZ2Q3a/oMPPqjnn39eTz31lNasWaMlS5boueee0z/+8Q9JUl5enqTwC612794tr9er9evXa9y4cVq8eLE2bNigd955R/fee69Gjx4dnYmMGjVKCxcu1Pjx47Vq1Srddddd2r9/v6655ppDjqV3796qqqrSxx9/HJ0d9+vXT++8807MbPnDDz9Unz59lJ6efshtRc5/3LhxWrNmjcaNG6fly5cfcX8MHz5cXq9X//M//6PVq1fr7bff1rPPPqu77rorZr1XX31V7733nlatWqWbb75ZzZs31+DBgyVJv/71rzVx4kS99dZbWr16tW677TbV1NRE/+BFv379VFxcrL/+9a9au3atHnzwQZWUlMRsPy8vT7Nnz9b27duPKaJ2u11/+9vf9MEHH+jKK6/UrFmztHHjRs2ePVvDhw8/7HukCwsLVVhYKJ/Pp82bN6uwsFCbNm2SFJ7ZDxs2TOvWrdPkyZNVWVmp7du3x9zRGDJkiN544w298cYb2rBhg/773//qqaee0iWXXHLUl6OuHTt2RM9r+/bt2rFjR4NO17FjR1100UW68cYbtWjRIn355Ze68847dcMNNygjI0Pz58/X448/rsWLF2vjxo167bXXlJCQoLy8vOP+/YIFxPMJbpz8DvWWkZKSEjNs2DCTkZFhkpOTzZlnnmmefPJJY4wxX3zxhenXr5/JyMgwKSkppm/fvmbevHnR00oyn3zySfT7yFug1q5dGz3s/fffN927dzdut9s0bdrUDBo0yHz11VfR4++//36TnZ0dfbvUpk2bTL9+/UxmZqZJTEw0HTt2NI899pjx+Xwx4546darp2LGjcbvdpnv37jHbPJTevXubNm3aRL+fN2+ekWT+8pe/RA/75S9/af785z8fcVtvv/22ad26tUlOTjZXX321GTNmzEEv/qpvf8+fP9/06tUr+vaY+t4uNWnSJHPuuedGL1thYWHMOk888YRp1apVvW+XMib8FpwWLVqYjIwMc//995trr7025sVfM2fONB06dDBOp/OY3i4V8c0335if//znJjs72yQmJppOnTqZhx56yJSVlR3yNPrOW+Qkmeuuu84YU/9b6CJLXX/6059Mu3btTGJiosnPzzcPPPCA8Xq9hzzPhrxd6rtLQkLCIbdX39ulLr/8cpOSkmIyMjJi3i61cuVK85Of/MRkZ2dH31I4bdo0Y8yRf79gfTZjjvIVLwCOSiAQUNOmTTV//vzoQ8ffN5vNpk8++UQDBw6My/kDaDgeygYaWVlZmf73f/83blEGcHJhxgycApgxAycP3i4FnAK4/w2cPHgoGwAACyHMAABYyEn3UHZCQoJycnLiPQwAAI7Jrl27DvuRrSddmHNyclRaWhrvYQAAcEw8Hs9hj+ehbAAALIQwAwBgIYQZAAALOemeYwaAU0EoFOL95ycxm812yM9ePxLCDAAW4vP5tGnTJvn9/ngPBcfJ5XIpNzdXbrf7qE5HmAHAQjZt2qS0tDRlZ2dHP5IUJx9jjPbs2aNNmzZFP5e9oQgzAFhEKBSS3+9Xdna2nE5unk922dnZKisrUygUOqqHtXnxFwBYROQ5ZWbKPwyRn+PRvlaAMAMAYCGEGQBQr27duqlbt27q3LmznE5n9Psrr7zyqLc1aNAglZSUHHG93/zmN3rvvfeOYbQnTnFxsV566aW4nT9PYgAA6lVYWChJKikpUc+ePaPf1ycQCBz2efHp06c36DzHjRt3dINsBJEw33TTTXE5f8IMAFZ16aXS+vWNs+22baUPPjjmk8+YMUP333+/zj33XC1atEhjx45VVVWVnn322ehbvcaPH6/BgwdLCv996BkzZqhjx47q27ev+vbtqy+//FJbtmzRkCFD9Nxzz0mSRowYob59++rWW2/VQw89pJKSEpWXl2v9+vVq1aqVpkyZoqysLHm9Xt1222364osvlJOTozPPPFN79+7VO++8EzPOYDCoO+64QzNnzpTb7ZbL5dJXX30ll8ulDz/8UOPGjVNtba1cLpeefPLJ6Hlv27ZN3bp1U5s2bfSvf/3rmPfTsSDMAIBjUlhYqOeeey4a1d27d2vEiBGy2WwqLi5W3759tXnzZjkcjoNOW1JSolmzZsnr9apjx4667rrrdPbZZx+03oIFCzR//nxlZWXpF7/4hV566SWNHTtWEydO1I4dO7Rq1Sr5fD71799fbdu2Pej0ixcv1uzZs7VixQrZ7XaVl5fL6XRq7dq1GjdunD7++GOlpaVpzZo1GjBggDZt2qQXXnhBDz30kObNm3fid1oDEGYAsKrjmNF+Hzp16qRzzz03+n1xcbGGDx+uLVu2yOl0avfu3dq8ebPy8/MPOu1VV10lh8Oh5ORknXXWWVq/fn29YR4yZIiysrIkSb1799batWslSTNnztQ111wjh8OhpKQkXXXVVVq4cOFBpy8oKFBNTY1GjhypAQMG6Kc//alsNps++ugjrV27Vv369YtZf8uWLcezS04IXvwFADgmqampMd//8pe/1B133KHly5ersLBQiYmJqq2trfe0iYmJ0f87HA4FAoGjWs8Y06C3lWVlZWnlypW66qqrtHLlSp1xxhnasGGDjDEaOnSoCgsLo8uWLVuUm5t7xG02NsIMADghysvLo7PjV155RRUVFY12XgMGDNDrr7+uYDCo2tpavfvuu/Wut3PnTlVXV2vQoEEaP368PB6PVq1apcGDB2vatGlauXJldN0FCxZIktLT07Vv375GG/uRnNoPZf/+99L27dLzz8d7JABw0nv66ac1dOhQtW7dWn369FGrVq0a7bxGjx6tZcuWqXPnzmrdurV69OihYDB40HobN27ULbfcokAgoFAopL59++qiiy6S0+nUq6++qhtuuEG1tbXy+Xw6++yz9dprr6l79+7Kz89X165d1a5du+/9xV82c5J9fInH41FpaemJ2Vi/ftKaNdKOHSdmewBwHILBoNasWaP27dvX+4IpxKqsrFRqaqpqa2s1dOhQjRgxQtdff328hxV1qJ/nkTp2as+YHQ6pnntYAABrC4VCuuCCC+Tz+VRTU6NBgwbpmmuuifewTgjCTJgB4KRjt9ujzwn/0JzaL/4izAAAiyHMhBkAYCGEmTADACyEMBNmAICFEGbCDAD1uvjii6N/B7uus84664jv7b3++uujp33hhRf01FNP1bveK6+8omHDhh1xLP/+979jXuz19ddfa/jw4Uc8XWMqLy/XE088ccK3S5iNCS8AgBgjR47U5MmTYw77+uuvtX37dg0dOrTB27n11lt19913H9dYvhvmnj176s033zyubR4vwtwYIm/4ZtYMAAe59NJLtXnzZi1ZsiR62N///ndde+21crlcWrZsmfr166cf/ehH6ty5s8aPH1/vdh555BHde++9kiSfz6dbbrlF7du314ABAzR//vzoeofa3ocffqgPPvhAjz32mLp166aXXnpJs2bNUs+ePaOnff3113XGGWfozDPP1E9/+tPoh1G88sorGjRokH71q1/pjDPOUM+ePVVcXFzvOP/whz+oU6dO6tatm7p166aNGzdKkhYuXKgLLrhAPXv21I9+9CP985//lBS+w1FeXq5u3brFjOV48T5mKRzmw3zANwDEw6VvX6r1exvn85jbZrXVB786/KdXud1ujRgxQpMnT9bTTz+t2tpavfPOO/ryyy8lSfn5+ZoxY4YSEhJUU1OjPn366Cc/+clhIzVp0iRt2LBBK1askN/vV//+/aN/X/tQ2xsyZIguvfRS9ezZU7fffrskadasWdFtLl++XGPHjtWiRYvUqlUrjRs3TqNGjdK0adMkSfPnz9eSJUuUl5enBx54QI8//rgmTZoUM669e/fqySef1LZt25SUlKTq6urox0TecsstmjZtmlq0aKHdu3erR48eOu+88/TCCy+oZ8+eKiwsPNrdf1jMmCVmzABwCCNHjtSbb74pn8+n999/X506dVKnTp0kSTU1Nbrpppt0xhlnqHfv3tq4ceMRIzVz5kxdd911crlcSk5O1ogRI6LHHcv2ItscOnRo9G9z33bbbfrss88U+YvTffv2VV5eniTp3HPP1fr1B9/ZSU9PV7t27TRixAhNmjRJZWVlSkxM1Ny5c1VcXKyLL75Y3bp108CBA2WMUVFRUcN24DE4taeJhBmAhR1pRvt96NKli9q2baupU6fq73//u0aOHBk97sEHH1Tz5s31zTffyOl06vLLLz/kxzxGHO7jGY5le5Ft1v0IyO9+HGRDPmLS4XBo3rx5mjt3rmbNmqXevXvr7bffljFGZ555pmbPnn3QaUpKSo44tmPBjFkizABwGCNHjtQf//hHLVy4UL/85S+jh+/du1cej0dOp1NFRUX65JNPjritCy+8UK+//roCgYBqamr01ltvNWh7h/soxgsvvFAffvihtm/fLin8KvALL7ywQZ/XHFFRUaEdO3aoX79++r//+z/17dtX33zzjfr06aO1a9fqs88+i65bWFgon8+n9PR0VVdXH/KzpI8VM2aJMAPAYVx11VW6++67deWVVyo1NTV6+EMPPaRrrrlGb775pvLz83XBBRcccVujRo3S0qVL1blzZ3k8HvXr1y/6IqvDbe+aa67R9ddfrylTpuj2229XQUFB9LguXbpo/PjxuuiiiyRJrVu31osvvnhUl3Hfvn0aNmyYqqqqZLPZ1K5dO1133XXKyMjQ1KlTNXbsWN19993y+/3Kzc3Vv//9bzVp0kTDhw/XGWecoZSUFH399ddHdZ6Hcmp/7ONtt0l//Wv4Yx+bNTsx2wSAY8THPv6wHOvHPvJQtsSMGQBgGYRZIswAAMsgzBJhBgBYBmGWCDMAS4i8ivgke+kPDiHyczyaV4dLvCo7/JUwA7AAu90ul8ulPXv2KDs7+6hv0GEdxhjt2bNHLpdLdvvRzYEJs0SYAVhGbm6uNm3apLKysngPBcfJ5XIpNzf3qE9HmCXCDMAy3G63CgoKFAqFeEj7JGaz2Y56phzR6GG+88479cEHH2jjxo1atmyZunbtGnP8o48+qkceeaTe4xpdZKeFQt/v+QLAERzrjTpOfo3+kx82bJjmzJkT/QPidS1evFjz5s07pqn+CcGMGQBgMY0e5v79+8vj8Rx0uNfr1ejRozVx4sT4vcCBMAMALCZuj5X89re/1YgRI9SmTZt4DYEwAwAsJy5h/uqrr7Rw4ULddtttR1x3woQJ8ng80aWysvLEDYQwAwAsJi5h/vzzz7V69Wq1adNG+fn5Ki0t1aBBg/TRRx8dtO6YMWNUWloaXep+sslxI8wAAIuJS5gfeOABbd26VSUlJSopKZHH49H06dN18cUXf78DIcwAAItp9DCPHj06+hFXAwcOjPkMzbgjzAAAi2n09zE///zzev755w+7TklJSWMPo36EGQBgMaf2O9gJMwDAYgizRJgBAJZBmCXCDACwDMIsEWYAgGUQZokwAwAsgzBLhBkAYBmEWSLMAADLIMwSYQYAWAZhlggzAMAyCLNEmAEAlkGYJcIMALAMwiwRZgCAZRBmiTADACyDMEuEGQBgGYRZIswAAMsgzBJhBgBYBmGWpFAovuMAAOBbhFlixgwAsIxTO8z2by8+YQYAWMSpHWZmzAAAiyHMEmEGAFgGYZYIMwDAMgizRJgBAJZBmCXCDACwDMIsEWYAgGUQZokwAwAsgzBLhBkAYBmEWSLMAADLIMwSYQYAWAZhlggzAMAyCLNEmAEAlkGYJcIMALAMwiwRZgCAZRBmiTADACzj1A4zn8cMALCYUzvMUnjWTJgBABZBmAkzAMBCCDNhBgBYCGEmzAAACyHMhBkAYCGEmTADACyEMBNmAICFEGaHQwqF4j0KAAAkEWZmzAAASyHMdjthBgBYBmFmxgwAsBDCTJgBABbS6GG+8847lZ+fL5vNpuXLl0uSamtrddlll6l9+/bq1q2bBg8erJKSksYeSv0IMwDAQho9zMOGDdOcOXOUl5cXc/ioUaNUVFSkwsJCDR06VKNGjWrsodSPMAMALKTRw9y/f395PJ6YwxITEzVkyBDZbDZJUu/evVVcXNzYQ6kfYQYAWIglnmN+5plndMkll8TnzAkzAMBC4h7mP/7xj1q7dq3GjRtX7/ETJkyQx+OJLpWVlSd2AIQZAGAhcQ3zk08+qffff18fffSRkpOT611nzJgxKi0tjS6pqakndhCEGQBgIc54nfGECRP09ttva8aMGcrMzIzXMAgzAMBSGn3GPHr0aHk8HpWWlmrgwIEqKChQaWmp7rnnHpWXl2vAgAHq1q2bevXq1dhDqR9hBgBYiM0YY+I9iKMRifwJc/750sqV0q5dJ26bAAAcwpE6FvcXf8UdM2YAgIUQZsIMALAQwkyYAQAWQpgJMwDAQggzYQYAWAhhJswAAAshzA6HFApJJ9e7xgAAP1CE2eEIfw2F4jsOAABEmA+EmYezAQAWQJgJMwDAQggzYQYAWAhh5jlmAICFEGZmzAAACyHMhBkAYCGEmTADACyEMNu/3QWEGQBgAYSZGTMAwEIIM2EGAFgIYSbMAAALIcyEGQBgIYSZMAMALIQwE2YAgIUQZsIMALAQwkyYAQAWQpgJMwDAQggzYQYAWAhhJswAAAshzIQZAGAhhJkwAwAshDATZgCAhRBmwgwAsBDCTJgBABZCmAkzAMBCCDNhBgBYCGEmzAAACyHMhBkAYCGEORLmUCi+4wAAQISZGTMAwFIIM2EGAFgIYSbMAAALIcyEGQBgIYTZ/u0uIMwAAAsgzMyYAQAWQpgJMwDAQggzYQYAWAhhJswAAAshzIQZAGAhjR7mO++8U/n5+bLZbFq+fHn08LVr16pPnz5q3769zjnnHK1cubKxh1I/wgwAsJBGD/OwYYCoVNUAACAASURBVMM0Z84c5eXlxRx+yy23aNSoUVqzZo3uu+8+jRw5srGHUj/CDACwkEYPc//+/eXxeGIO27lzpxYvXqwRI0ZIkq644gpt2LBBJSUljT2cgxFmAICFxOU55s2bN6tly5ZyOp2SJJvNptzcXG3atOn7HwxhBgBYSNxe/GWz2WK+N8bUu96ECRPk8XiiS2Vl5YkdCGEGAFhIXMLcunVrlZaWKhAISApHefPmzcrNzT1o3TFjxqi0tDS6pKamntjBEGYAgIXEJczNmjVT9+7d9cYbb0iS/vnPfyo/P1/5+fnf/2AIMwDAQho9zKNHj5bH41FpaakGDhyogoICSdKkSZM0adIktW/fXo899phefvnlxh5K/QgzAMBCbOZQT+5aVCTyJ8yWLZLHI915p/SXv5y47QIAUI8jdYy//MWMGQBgIYSZMAMALIQwE2YAgIUQZsIMALAQwkyYAQAWQpgJMwDAQghzJMyhUHzHAQCACDMzZgCApRBm+7e7gDADACyAMNts4TgTZgCABRBmKfxwNmEGAFgAYZaYMQMALIMwS8yYAQCWQZglwgwAsAzCLBFmAIBlEGaJMAMALIMwS4QZAGAZhFkizAAAyyDMEmEGAFgGYZYIMwDAMgizRJgBAJZBmCXCDACwDMIsEWYAgGUQZokwAwAsgzBLhBkAYBmEWSLMAADLIMwSYQYAWAZhlggzAMAyCLNEmAEAlkGYJcIMALAMwiwRZgCAZRBmKRzmUCjeowAAgDBLYsYMALAMwiwRZgCAZRBmiTADACyDMEuEGQBgGYRZIswAAMsgzFI4zMaEFwAA4ogwS5L9293ArBkAEGeEWQrPmCXCDACIuwaHedKkSdq3b58kafTo0erZs6dmz57daAP7XhFmAIBFNDjMzz//vDIyMvTll19q+fLlGjdunO69997GHNv3hzADACyiwWF2Op2SpM8++0zXXnutBg0apEAg0GgD+14RZgCARTQ4zHa7Xe+8847+8Y9/6MILL5Qk+Xy+RhvY94owAwAsosFhfu655/TOO+/o5ptvVn5+vtasWaMBAwY05ti+P4QZAGARzoau2Lt3b/373/+WJBlj1KJFCz377LONNrDvFWEGAFhEg2fMI0eOVHl5uXw+n7p166bmzZtr4sSJjTm27w9hBgBYRIPDvGjRImVmZmr69Onq3r27tm/frkmTJh3XmU+fPl09evRQ9+7d1bVrV7366qvHtb1jRpgBABbR4Ieyzbd/rnL27NkaOnSo0tPTZbcf+98nMcbo6quv1syZM3XmmWeqpKREHTt21OWXX660tLRj3u4xIcwAAItocFlPO+003XrrrZoyZYoGDhwov9+v4AkIWXl5uSRp//79ys7OVkJCwnFv86gRZgCARTR4xvzmm2/qjTfe0PXXX6/MzEyVlJRozJgxx3zGNptN7777ri6//HKlpKRo7969ev/99+V2u495m8eMMAMALKLBM+amTZvqlltukc1m04IFC9S8eXNdf/31x3zGgUBA48eP13/+8x9t3LhRn376qa677jqVlZXFrDdhwgR5PJ7oUllZeczneUiEGQBgEQ0O89y5c9W2bVvdeuutGjVqlAoKCvTVV18d8xkXFhZq69atOu+88yRJZ599tlq2bKklS5bErDdmzBiVlpZGl9TU1GM+z0MizAAAi2hwmMeMGaMpU6bom2++UWFhoaZMmaK77777mM+4devWKi0tVVFRkSRp3bp1Wr9+vdq3b3/M2zxmhBkAYBENfo65trY2OruVpD59+qimpuaYz7h58+aaNGmShg0bJrvdLmOMJk6cqFatWh3zNo8ZYQYAWESDw5ycnKwZM2Zo4MCBkqRZs2YpJSXluM78V7/6lX71q18d1zZOCMIMALCIBof5mWee0RVXXKGEhATZbDZ5vV69+eabjTm27w9hBgBYRIPD3LNnT61bt05FRUUyxqhDhw4qKCjQpk2bGnN8349ImEOh+I4DAHDKa3CYJcnlcqlr167R7yN/Deykx4wZAGARx/43NRX+IyE/CIQZAGARR5wxr1y58pDHBQKBEzqYuCHMAACLOGKYf/rTnx7yuMTExBM6mLghzAAAizhimDds2PB9jCO+CDMAwCKO6znmHwzCDACwCMIsSZHPlSbMAIA4I8wSM2YAgGUQZokwAwAsgzBLhBkAYBmEWSLMAADLIMwSYQYAWAZhlggzAMAyCLNEmAEAlkGYJcIMALAMwiwRZgCAZRBmiTADACyDMEuEGQBgGYRZIswAAMsgzBJhBgBYBmGWCDMAwDIIs0SYAQCWQZglwgwAsAzCLBFmAIBlEGbpQJhDofiOAwBwyiPMEjNmAIBlEGaJMAMALIMwS4QZAGAZhFkizAAAyyDMEmEGAFgGYZYIMwDAMgizRJgBAJZBmCXCDACwDMIsSfZvdwNhBgDEGWGWmDEDACyDMEuEGQBgGYRZIswAAMsgzBLPMQMALIMwRzgchBkAEHeEOYIwAwAsgDBHEGYAgAUQ5gjCDACwAMIcQZgBABZAmCMIMwDAAghzBGEGAFhAXMPs9Xp1++23q127durSpYtGjBgRv8EQZgCABTjjeeYPPPCA7Ha71qxZI5vNpm3btsVvMIQZAGABcQtzVVWVJk+erNLSUtlsNklSixYt4jUcwgwAsIS4PZS9fv16ZWdn6w9/+IN69uypfv366dNPPz1ovQkTJsjj8USXysrKxhkQYQYAWEDcwuz3+1VcXKzOnTvr66+/1nPPPaerrrpKu3btillvzJgxKi0tjS6pqamNMyCHQwqFGmfbAAA0UNzCnJeXJ7vdruHDh0uSzjrrLLVp00YrVqyIz4CYMQMALCBuYW7atKkuvPBCTZ8+XZK0ceNGbdiwQR06dIjPgAgzAMAC4vqq7BdeeEE33nij7r//fjkcDr344ovxewGYwyF5vfE5bwAAvhXXMJ9++umaNWtWPIdwADNmAIAF8Je/IggzAMACCHMEYQYAWABhjiDMAAALIMwRhBkAYAGEOYIwAwAsgDBH2O2EGQAQd4Q5ghkzAMACCHMEYQYAWABhjiDMAAALIMwRhBkAYAGEOYIwAwAsgDBHRD6P2Zh4jwQAcAojzBEOR/hrKBTfcQAATmmEOSISZh7OBgDEEWGOIMwAAAsgzBGEGQBgAYQ5gjADACyAMEcQZgCABRDmCMIMALAAwhxBmAEAFkCYIwgzAMACCHMEf2AEAGABhDmCGTMAwAIIcwRhBgBYAGGOIMwAAAsgzBGEGQBgAYQ5gjADACyAMEcQZgCABRDmCMIMALAAwhxBmAEAFkCYIwgzAMACCHOE/dtdQZgBAHFEmCOYMQMALIAwRxBmAIAFEOYIwgwAsADCHEGYAQAWQJgjCDMAwAIIcwRhBgBYAGGOIMwAAAsgzBGEGQBgAYQ5gjADACyAMEcQZgCABRDmCMIMALAAwhxBmAEAFkCYIwgzAMACCHMEYQYAWABhjoiEORSK7zgAAKc0S4T50Ucflc1m0/Lly+M3CGbMAAALiHuYFy9erHnz5ik3Nze+AyHMAAALiGuYvV6vRo8erYkTJ8pms8VzKIQZAGAJcQ3zb3/7W40YMUJt2rQ55DoTJkyQx+OJLpWVlY0zGMIMALCAuIX5q6++0sKFC3Xbbbcddr0xY8aotLQ0uqSmpjbOgAgzAMAC4hbmzz//XKtXr1abNm2Un5+v0tJSDRo0SB999FF8BkSYAQAWELcwP/DAA9q6datKSkpUUlIij8ej6dOn6+KLL47PgAgzAMAC4v6qbMsgzAAAC3DGewARJSUl8R0AYQYAWAAz5gjCDACwAMIcQZgBABZAmCPs3+4KwgwAiCPCHMGMGQBgAYQ5gjADACyAMEcQZgCABRDmCMIMALAAwhxBmAEAFkCYIwgzAMACCHMEYQYAWABhjiDMAAALIMwRhBkAYAGEOYIwAwAsgDBH8Cc5AQAWQJgjbLZwnAkzACCOCHNdDocUCsV7FACAUxhhrsvhYMYMAIgrwlwXYQYAxBlhroswAwDijDDXRZgBAHFGmOsizACAOCPMdRFmAECcEea6CDMAIM4Ic12EGQAQZ4S5LsIMAIgzwlwXYQYAxBlhroswAwDijDDXRZgBAHFGmOvi06UAAHFGmOtixgwAiDPCXBdhBgDEGWGuizADAOKMMNdFmAEAcUaY6yLMAIA4I8x1EWYAQJwR5roIMwAgzghzXYQZABBnhLkuwgwAiDPCXBdhBgDEGWGuizADAOKMMNdFmAEAcUaY63I4pFAo3qMAAJzCCHNdDodkTHgBACAOCHNdDkf4Kw9nAwDihDDXRZgBAHFGmOsizACAOCPMdRFmAECcxS3MtbW1uuyyy9S+fXt169ZNgwcPVklJSbyGE0aYAQBxFtcZ86hRo1RUVKTCwkINHTpUo0aNiudwCDMAIO7iFubExEQNGTJENptNktS7d28VFxfHazhhhBkAEGeWeY75mWee0SWXXHLQ4RMmTJDH44kulZWVjTcIwgwAiDNLhPmPf/yj1q5dq3Hjxh103JgxY1RaWhpdUlNTG28ghBkAEGfOeA/gySef1Pvvv68ZM2YoOTk5voMhzACAOItrmCdMmKC3335bM2bMUGZmZjyHEkaYAQBxFrcwl5aW6p577tHpp5+uAQMGSJISEhI0f/78eA2JMAMA4i5uYfZ4PDJW+7AI+7dPuRNmAECcWOLFX5bBjBkAEGeEuS7CDACIM8JcF2EGAMQZYa6LMAMA4oww10WYAQBxRpjrIswAgDgjzHURZgBAnBHmuggzACDOCHNdhBkAEGeEuS7CjHj4/HPpN7+RamriPRIAFhD3T5eKp0+LP9Xu6t2y2+zhxbdE9g6Sc+Jdcr7dVE6bQy6bQ86UNLmym8mZ00yunNPkSsuUyx+U2xuQy+uX2xeSKyVN7qymcmU1lS0zU0pKCofebg8vNpvk9x9YAgEpMVFKT5fS0g7cKcCp5bXXpJEjw9eHr7+W/vOf8PUCcWOM0Zebv9S6snUqaFKg81qfJ5vNFu9h4RRiM5b7g9WH5/F4VFpaekK21W9yP83ZNOeEbKsuR0hyhsJf7Sa8OMyB/9vNgXWcIckVklzGJofNLskWjvi3wusaOYNGjqCRsdsUcNgVcNoUcNhkt9l1ms+tFv5EtQwkqUUoWR57plq7c9Q6pYWapjVX0IS0bs9aragq0YrgVm207Vdzn1t5gRTlBVOVF8qQOyNLNc2bqDaniWqapEupKWrmd6u516WM6pBs1dVSQoJqk1zanRDQLldAvmS3nOlZcmVkyZXZRI70TAUUUiAUUCAUkD/oV8iEYhaXw6XspGxlJ2crKzFLDvvBd0hCJqQKb4X2efepvLZc1f5qGWNkFL6q2mRTbkauWqa1bNANZiAUUG2gVi67SwnOhEOuFzKh8D63NeyBJH/Qr0pfpVLdqXI5XEdcv9pfrTV71mj17tWq9FbINu1D2f/1b9mzmii1oJN+NOVL5Z87WLZ//VtKODDOkAlp075NkqS8jDwi0Yg2lm/UoDcGaUP5BrkdbvmCPrXJbKPpI6YrLzMv3sP7wQqZkGr8NUp2Jcdcv40x2lm1U6t3r9bq3atV7a9WojMxuiS5ktQkqUl0yU7KPuzveEMZYxr19+xIHTulwzyrZJZ2V++OCUcwFFTQBOUP+hQI+uX3exWoqlBg31759++Vf3+5/N4a+Z2S32GTzyH57EZ+v1d+X438vlr5/LUKBgMKKaSQjIImpKBCCtlsCtmloE0K2oyCoaD8Ib8CoaD8JqCg+fYhdBP+x0gK2b5d3y4FbEZ2cyDozqBRwGa0PSmoGmf9P8aEQHhzvuN4bMQdkLJrpAq3VHn81/kom5HSlSCbbArJhPeVQqpVQKYBvxPprlR1zmqvLtmdlJ6cpR3eMu2o2qHtldu1q3qXqv3Vqg3UKhAKHLgsDrfS3GlKT0iX2+FWlb9KVb4qVfur5Q16o+tFHkVx2V1KdCYqwZmgRGeiHDaHKnwVqvBWqCYQfujZJpuapTRTy7SWapHWQhkJGQfunIT8qvZXa13ZumhcD6dplXR2IEfdB9+gnbVlWrZzmVbsWqFKX6UkKSc5R708vdSrVS91zumsrRVbtb5svdbvDS/egFcuh0tOuzM69vSEdGUkZigzIVNpCWkKmZB8QV90SXAkqFlKM+Wk5CgnOUdNkprIaXfKYXfIYXPIYXco1Z2qrMQsZSZmKtWdKn/Ir+K9xVq7Z63Wla3TlootapnWUu2atFNBkwK1yWqjRGeijDHyh/zyBX2q9FVqW8U2bavcFv4ZVe1STkqOTs86XW2z2qpVeivZbXb5gj7trt6tXVW7tKdmj8pry1VeW659tfu0z7tPDptDaQlpSnOnKS0hTVmJWcrNyFVuRq6SXEmSwjesWyq2aPnO5Vq5a6X8Qb9OSz1NLdJaqEVqCzVJaqKgCUb3QSAUUE5yjga8OkDry9YrYA5cZxw2h05LPU239rhVKe4UZSWF90NWYlbM/1PdqdEb85AJqTZQq2p/tXZW7dTWiq3aWrFV2yq2qSZQoyRnkpJdyUpyJclpd2pP9Z7wZa7eFb1Ncjlcctld0a9OuzP8c/n2ZxIIBeQL+qL712l3hveJO02p7lSlulOV4ExQgiNBCc4EuR1u7avdp13Vu7Szaqd2Ve+Sw+ZQ++z2ap/dXh2yO6hNVhtJki/okzfglTfo1bqydSrcXhhdtlRsUWZippokNVFWYpaaJDVRTnKOmqc2V/OU5mqW0kxOu1N7a/eqrKZMe2v2qspfpVR3qtIT0pWekK40d5pK95dq+a7l0Z9Rtb9aTrszus1kV7JKyku0t3bvkW8M6kh1p4avz8k5apbSTC1SW0SvH7kZuWqR1kLV/urodaq8tlwb923U2rLwdXntnrWq8FXo9KzT1T67vdo1aad2Tdqpf15/dcrpdFRjORTCfASRK1+Ey+5SkitJNf4a+UP+6OGRK3eVr+pAQCUlOhPldrhV6auMzrgkKdmVLKfdqf3e/THnl+JKkd1mV4WvIubwNHf4BrPKXxVzeHpCugKhgKr91dHD7Da7Ut2p8gV9qg3Uyhijfd592lW1S+W15dpQtl4bd67RlrKN2rJ/i+w2u85o2U3tWp6hdjkdlJ+Zr11Vu7S9cru2VW7TurJ18ntrlFjjV3K1XynVftm8Xm21VWqHrVq7TJV2hyqV4UhWM3uaMkNu5YSSlOgLKlBTpZDXK39ttfzeKjl9Qbn9QTl9Abl8QTmrvbJXVcvu9cpuJK9D2pMs7UkKf92bKNkU+2hCsl9K99uV4UgJ/xLLLdu27bJXh0MYtEsbMqUVzaSVOdKulAP7K6NWal7rVI7PoeTakJJrAkryGSUEJb9dqkiQ9ifaVJFkl9dtV4pxKdnmVrLNrSSbWzavV6GaGpmaagVNSH6HVOuUvAkO1SY4FHA5lBZwKC1gV7rfodSgXfvcRtuSgtqa6NNWl1c++7czb9nkkkMJdpfybU3UwZuqjnud6rh+n7LXlirYo7uqx96lUFKiymrKtGRboRbP/acKnbujd6SaOjN0RlKuznC3ltcEtdBXrKVVxQqY2NdBuOwu5aa3VrI7WaFvYxi5bu+v3afqwIl7/tphc8jIxFzfv8smm1wOl3xBX4O363a4lehMPOh35mjkJOeoeUpzbdq/6bi2cywcNoeSXcmqDdTG3HYcy3YcdsdR7bvvS5vMNsrLzNN+736V1ZSprKbsuPdzi9QW6tqsq05LPU37vPuiMa/wVSgvI0+dmnZSx6Yd1aFpB2UmZqo2UCtvwKvaQK0qfZXROwBlNWXaUxO+g7Ozamd0qXvH/EiapTRTuybtlJGYEb3DGzn9EwOf0Njzxh7XZY04UsdO6eeYJWn8nPF69PNHo9+P7D5SL136ku746A69/M3L0cMfPv9hPfLjR3T5u5fr/63/f9HD/3bJ33TTj25Sr5d6aeWuldHDPx7+sQYVDJJngicmwsv/Z7laZ7RWxmMZMePY98A+bd63WV3/2jV6WJo7Tfv/d78+Lf5Ug98cHD28c05nrbhthV5b8ppunnpz9PCL2l6k6SOm65FNX+gPC/8cc5meuPQ53fTBTRr14a0HXaZBbwyq9zJ1mdil3suUPj499jLddeTL5AxKWTXSaUrR0lsK9UXxLI364GbZTfhRgTbZbfXhNR/rnVVTdNucB7U3KSTZKnRR23PDl2nmw3pp6u901g6p607p4pSz9HzTn2jGqg/1zZ6VcoSklhXS2Umnq62rmdZvXaEtqlB5orQ3SerZ8QJ1adJB/134psz+/cqoDSrDG1R7Z5aSqnwK7tsph5EqXdKmDCm3ax+589vq5eWvq2m1lF0dVNPqoLq6PQqYgLZXbJexhWf9bmPTaY4MBasDsvtC8jnCT0/YjZEU+HbZEt0v+1NdSr/+dv3uZ5l6eNp1MT+n+X/YrtkD2ytrZbGaV0nNqvZJWvbtElbrlL45TSpqKnn2SwVlUut9fjlMsSQp6HbJkZSsHcH9cgWMmtSG75TsTwjfMXGEJHcwvLhCUnWiQ1s6tNK/kjdpRTOpNENKCTl1xek/1Y49G7WqtFBeh1TtkgJJbmVlt1JVzX4lb9ujtmVSp11S58oEBVq30rzUfVqQuEebMox8Dp8yXalqmZij8srd8lZXKLM2fD3onpCns1Pba8aehSqyl2tnqrQjxaek5ATlOvO1t2yb5PXKHQyP9+LTL1LXpp00ceFE7bf5VeMMj2f4OTfK77Lr+cKX5HVKNZW7tNG1S93S2un0lDP0dfGXcn37CFOC3a1rzrpGS3Yt15xt88OPRtml1KR0XdL553pv+0wt824K31P8jgQ5dZ/zfF0UaqPyQKX2Biu1N1StclcwfB1zBVXu9KvKHlRiYqqSktKUmJyuRHeKmiU3VUtHplqYVLUMJCk5aFeNPahqBVRjCyhgl5o405TjzlRTZ4YyHSmyORwyDoeCDpv8dskf8ilYVaVAdYWC1VUK1lbL5UqUKylV7qRUuZJTFXA7VeEMar/drwq7X1W2gLx17qD5gj6lJ6RHZ5M5KTnyBX1au2etinatUlHpEm3cvU4Om11uh1tuu1sJzgS1Tmmh7tlddWZ2Z2UmZYVfM+NySU6n5HTKbzPa7S/Xjprd2lmzWzsqdyhogjEz6hR3iip9ldrv3a99tfu037tfLdJaqEtOF2UnZx+8w08QY4x2V+/Wpn2bosv2yu1KcacoMzFTGQkZykjMkCfdo4ImBUpPSI85fSAU0MbyjVqzu0jts9o22ji/ixnzD2DGHOGwOZTiTuEyHctlqt0n1daGX3hlsx37ZfJWSpWVsu3aLceeMiWXVymwd4+82ZkyrT0KeVrJkZp++MtUUyG98YZse/fKJCbImZwmV0qavDWVMmV7ZCvbK9vevXLsr5RDNvlDAcmY8BIMyFHrl93rVaC6SnI4FMrLlcnLlatNgWwej2r275Ft127Z9uyRbfceuUs2S8uXy1ZcrKNhbDaZrEyZrCwpLU2OqmqZ8nKpvFw2/7HPGONlTq504bX1P+3jDkifvib1PfKzEbESEiSv98jrNZbU1PCLSyOL0xl+DUtkqamRtm+Xdu48Me9GsdvDL2R1Og/E2+UKL273gcXlCp+f1xv+vfN6w9/XXTfyNSHhwOkSE8PfJyaGF5cr/GJan+/AC2sTEw9c7tRUKSUldnE6pY0bpXXrpPXrpQ0bwuNu3vzAkpAgbd0qlZYeWP70J+m2245/H4mHsgE0VGWltGqVtGlT+N0CWVlSZqaUkRG+MTNGCoXCi8sVPtxezwvljAnf4Pv94Rv/yLsS6v6/vsOk8I1zba1UXR3eRk1N7I135KvPd+BrMHjgBjtyI+71HthGVVX4PFJSDtxQu93h46qrw0tVlUxtrTpVjNd6s0cBHbjz5pRdBYmttPLHU2SLxCASnZoaae9eqays/q/l5VJycnhfNmkS/pqQEPsOjWDwwH6I7Atjwq/UDwQOBDM5+cCSkBA+rrY2vNTUHPgaWaqrpYqK2CVQ506cFN5O8+bSaaeFvzZtGg5r5OccCh34uUe+RsYUGV/kMkS+r3v4dxef78DidB6IbEJC+HzrW7fuzzvy/xPF5ZLy88P/37FD2v+dh+UzMiSPJ7zcfLN0xRUn5GwJMwA0UMyrsu1u+UI+nZ51uqaPmK7cjNx4Dw9S+M6Bzxe+I+L3x86wnc5wvCsqwnc0I0tV1YHF55Nat5YKCsLBrftW1Zqa8KMHtbVSy5bhWXcjIMwAcBR4HzMaGy/+AoCjYLPZ1De3r/rm9o33UHCK4k9yAgBgIYQZAAALIcwAAFgIYQYAwEIIMwAAFkKYAQCwEMIMAICFEGYAACyEMAMAYCGEGQAACyHMAABYCGEGAMBCCDMAABZCmAEAsBDCDACAhRBmAAAsxGaMMfEexNFISEhQTk7OMZ++srJSqampJ3BEiGDfNi72b+Ni/zYe9m2sXbt2yev1HvL4ky7Mx8vj8ai0tDTew/hBYt82LvZv42L/Nh727dHhoWwAACyEMAMAYCGORx555JF4D+L7du6558Z7CD9Y7NvGxf5tXOzfxsO+bbhT7jlmAACsjIeyAQCwEMIMAICFnDJhXrt2rfr06aP27dvrnHPO0cqVK+M9pJNWbW2tLrvsMrVv317dunXT4MGDVVJSIknauXOnBg8erHbt2qlr166aM2dOfAd7knv00Udls9m0fPlySVyPTwSv16vbb79d7dq1U5cuXTRixAhJ7NsTZfr06erRo4e6d++url276tVXX5XEbcNRMaeIAQMGmMmTJxtjjJkyZYrp3bt3fAd0EqupqTHTpk0zoVDIGGPMs88+a37yk58YY4y54YYbzMMPP2yMMWbBggUmNzfX+P3+eA31pLZo0SIzePBgk5uba5YtW2aM4Xp8Itx1113mjjvuiF5/t27daoxh354IoVDINGnSxCxZssQYY8yGDRtMQkKC0c0ssQAABZhJREFU2b9/P7cNR+GUCPOOHTtMRkZG9EoQCoVM8+bNzYYNG+I7sB+IhQsXmrZt2xpjjElJSTE7d+6MHnf22WebmTNnxmlkJ6/a2lrTu3dvU1xcbPLy8syyZcu4Hp8AlZWVJiMjw1RUVPz/9u4vpKk3juP4+1SkRMJgEbX8cxbmxZiu2pJiMy+igkCIKAkUvO+m2y5iRGTdhFDWbdE/F2JCEKWUpFQE2YXFSKNmWxsyKi/CEKLZ87sQR/6C+Fn7tek+r8vzjLPv+fLwfHm+Zztn3nHlNjfmCvPQ0JAxxpgXL14Yl8tlvn79qrVhAYqilZ1MJnG5XKxYsQIAy7KorKzk/fv3eY5saTh//jxNTU1MTk7y/fv3eY9MtW1bef4N4XCY1tZW3G539pjm8Z+LxWI4nU5OnTpFIBCgoaGBgYEB5TZHLMuiu7ubAwcOUFVVRSgU4sqVK0xNTWltWICiKMwwO2F+ZPQvsZw4ffo0b968ob29HVCec+Hp06cMDw9z5MiRn8aU3z/z7ds3xsfH8Xg8PH/+nAsXLnD48GEymYxymwOZTIYzZ85w+/ZtEokEAwMDtLW1AZq7C1EUhbmiooJUKkUmkwFmJ0QymaSysjLPkS1uZ8+epbe3l3v37rFq1SqcTicw+4D2OYlEQnleoKGhIcbGxnC73di2TSqVYu/evUSjUc3jP1RVVcWyZctoaWkBwOfz4Xa7SSQSym0OjIyMMDExQTAYBGDbtm24XC5evnwJaG34r4qiMK9du5YtW7Zw/fp1AG7duoVt29i2nd/AFrGOjg4ikQj379/H4XBkjx86dIiLFy8CMDw8TDqdJhQK5SvMRenYsWNMTEwQj8eJx+OUl5fT399PW1ub5vEfWrNmDbt27aK/vx+YLQ7v3r2joaFBuc2BuU3Q69evAXj79i2xWIyamhqtDQuRv9vbf9fY2JjZvn272bRpk/H7/SYajeY7pEUrmUwawGzcuNH4fD7j8/lMfX29McaYdDptdu/ebaqrq43H4zGDg4N5jnbxm/vxlzGax7kQi8VMY2Oj8Xq9xufzmd7eXmOMcpsrXV1dxuv1mrq6OlNbW2sikYgxRmvDQuiRnCIiIgWkKFrZIiIii4UKs4iISAFRYRYRESkgKswiIiIFRIVZRESkgKgwi4iIFJAV+Q5ARHLLtm1KS0spLS3NHuvq6sLj8eTsO+LxOIFAgE+fPuXsnCIyS4VZZAnq6enB6/XmOwwR+Q1qZYsUCcuyOHHiBMFgkJqaGiKRSHasr6+PrVu3UldXR2NjI69evcqOXb58mc2bN+Pz+QgEAsTj8exYOBzG7/dTXV3N3bt3/+bliCxZ2jGLLEEHDx6c18p+9uwZMFucnzx5wvj4OPX19YRCIUpKSmhtbeXhw4fU1tZy48YNmpubiUajDA4O0t7ezqNHj1i/fj3T09MAfPjwgcnJSfx+PydPnqSvr4+jR4+yb9++vFyvyFKiR3KKLDG2bXPnzp2fWtmWZZFKpdiwYQMA+/fvp7m5mbKyMs6dO8eDBw+yn3U4HIyOjtLR0UFZWRnhcHjeueLxOF6vly9fvgDw+fNnnE5n9u1MIvL71MoWKWKWZWGM+elduXNjv/Ljjnz58uXMzMzkPD6RYqTCLFJELl26BMzueB8/fkwoFGLHjh2MjIwwOjoKwM2bNykvL2fdunU0NTVx9epV0uk0ANPT09l2toj8P3SPWWQJ+vc95s7OTgBKSkoIBoN8/PiRzs5OKioqALh27RotLS3MzMzgcDjo7u4GYOfOnRw/fpw9e/ZgWRYrV66kp6fn71+QSBHRPWaRImFZFlNTU6xevTrfoYjIL6iVLSIiUkDUyhYpEmqOiSwO2jGLiIgUEBVmERGRAqLCLCIiUkBUmEVERAqICrOIiEgBUWEWEREpIP8A2C8bBrbpuXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 560x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model accuracy\n",
    "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.title('resnet50 w/ dropout FC 128 FE accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs_fe, tra_acc_fe, 'r', label='Training set')\n",
    "plt.plot(epochs_fe, val_acc_fe, 'g', label='Validation set')\n",
    "plt.plot(opt_epoch_fe, val_acc_fe[opt_epoch_fe-1], 'go')\n",
    "plt.vlines(opt_epoch_fe, min(val_acc_fe), opt_val_acc_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.hlines(opt_val_acc_fe, 1, opt_epoch_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Model loss\n",
    "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.title('resnet50 w/ dropout FC 128 FE loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs_fe, tra_loss_fe, 'r', label='Training set')\n",
    "plt.plot(epochs_fe, val_loss_fe, 'g', label='Validation set')\n",
    "plt.plot(opt_epoch_fe, val_loss_fe[opt_epoch_fe-1], 'go')\n",
    "plt.vlines(opt_epoch_fe, min(val_loss_fe), opt_val_loss_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.hlines(opt_val_loss_fe, 1, opt_epoch_fe, linestyle=\"dashed\", color='g', linewidth=1)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
