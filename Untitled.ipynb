{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.applications import vgg16\n",
    "from sklearn import *\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization, GlobalAveragePooling2D  \n",
    "from tensorflow.keras.backend import batch_normalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from packaging import version\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 508s 9us/step\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dahyun\\anaconda3\\envs\\mammo\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ROWS=224\n",
    "COLS=224\n",
    "target = (ROWS,COLS)\n",
    "\n",
    "#load model\n",
    "input_shape = (ROWS,COLS,3)\n",
    "vgg=vgg16.VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "vgg_model=Model(vgg.input, output=vgg.layers[-1].output)\n",
    "\n",
    "#freeze all but last layers\n",
    "# 0-15: train only the last convolutional layer (block5_conv3, conv2, conv1) \n",
    "for layer in vgg_model.layers[:15]:\n",
    "\tlayer.trainable = False\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN / TEST GENERATORS\n",
    "train_datagen = ImageDataGenerator(\n",
    "#\tfeaturewise_center=True,\n",
    "\tsamplewise_center = True,\n",
    "\tsamplewise_std_normalization = True,\n",
    "\tshear_range=0.5,\n",
    "\trotation_range= 40,\n",
    "\twidth_shift_range=0.25,\n",
    "\theight_shift_range=0.25,\n",
    "\tzoom_range= [0.5,1.5],\n",
    "\thorizontal_flip=True,\t\n",
    "\tfill_mode='nearest',\n",
    "#\tpreprocessing_function=preprocess_input\n",
    ")\n",
    "train_datagen.mean = [103.939, 116.779, 123.68]  #this is the global mean of the training set calculated by MATLAB\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#\tpreprocessing_function=preprocess_input,\n",
    "\tsamplewise_center = True,\n",
    "\tsamplewise_std_normalization = True,\n",
    "#\tfeaturewise_center=True\n",
    ")\n",
    "test_datagen.mean = [103.939, 116.779, 123.68]  #this is the global mean of the training set calculated by MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# This makes the batches for training / validating / testing\n",
    "# The validation images are taken from the train images in a split using subset attribute\n",
    "train_batches = train_datagen.flow_from_directory(train_path, target_size = target, batch_size=32, class_mode='categorical',shuffle=True)\n",
    "valid_batches = test_datagen.flow_from_directory(test_path, target_size = target, batch_size=32, class_mode='categorical',shuffle=True)\n",
    "test_batches = test_datagen.flow_from_directory(test_path, target_size = target, batch_size=1, shuffle=False, class_mode='categorical')\n",
    "\n",
    "#train data\n",
    "X_train = np.load(os.path.join(\"Data/256\", \"X_train.npy\"))\n",
    "y_train = np.load(os.path.join(\"Data/256\", \"train_labels_multi.npy\"))\n",
    "y_train_bi = np.load(os.path.join(\"Data/256\", \"y_train.npy\"))\n",
    "\n",
    "#test data\n",
    "X_test = np.load(os.path.join(\"Data/256\", \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(\"Data/256\", \"y_test_labels_multi.npy\"))\n",
    "y_test_bi = np.load(os.path.join(\"Data/256\", \"y_test.npy\"))\n",
    "\n",
    "#validation data\n",
    "X_val = np.load(os.path.join(\"Data/256\", \"X_val.npy\"))\n",
    "y_val = np.load(os.path.join(\"Data/256\", \"y_val_labels_multi.npy\"))\n",
    "y_val_bi = np.load(os.path.join(\"Data/256\", \"y_val.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: <keras.engine.training.Model object at 0x000001F1B55B8400>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-67988d3668aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mammo\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mammo\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    159\u001b[0m       raise TypeError('The added layer must be '\n\u001b[0;32m    160\u001b[0m                       \u001b[1;34m'an instance of class Layer. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                       'Found: ' + str(layer))\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <keras.engine.training.Model object at 0x000001F1B55B8400>"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024,activation='relu', kernel_regularizer=regularizers.l2(1)))\n",
    "#model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Optimization - Fillting\n",
    "optimizer = Adam(lr=1e-4)\n",
    "model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STEP_SIZE_TRAIN=train_batches.samples//train_batches.batch_size\n",
    "STEP_SIZE_VALID=valid_batches.samples//valid_batches.batch_size\n",
    "\n",
    "#this is to save the results\n",
    "file_path='weights.best.vgg16.hdf5'\n",
    "\n",
    "# Learning Rate Reducer\n",
    "learn_control = ReduceLROnPlateau(monitor='val_acc', patience=10,verbose=1,factor=0.1, min_lr=1e-7)\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor='val_acc', mode='max', patience=20)\n",
    "callbacks_list = [learn_control, checkpoint, early]\n",
    "\n",
    "history = model.fit_generator(train_batches, steps_per_epoch = STEP_SIZE_TRAIN, validation_data = valid_batches, validation_steps=STEP_SIZE_VALID, shuffle=True, callbacks=callbacks_list, epochs=150, verbose=1)\n",
    "#history = model.fit_generator(train_batches, steps_per_epoch = STEP_SIZE_TRAIN, validation_data = valid_batches, validation_steps=STEP_SIZE_VALID, shuffle=True, epochs=200, verbose=1)\n",
    "\n",
    "#Check testing using the best weights from the file\n",
    "model.load_weights(file_path)\n",
    "\n",
    "result=model.evaluate_generator(generator=test_batches,steps=1)\n",
    "print('Loss: ',result[0])\n",
    "print('Accuracy: ',result[1])\n",
    "\n",
    "test_batches.reset()\n",
    "pred = model.predict_generator(test_batches, verbose=True, workers=2)\n",
    "\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "labels = (test_batches.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "true_classes = test_batches.classes\n",
    "class_labels = list(test_batches.class_indices.keys())\n",
    "report = metrics.classification_report(true_classes, predicted_class_indices, target_names=class_labels)\n",
    "print(report) \n",
    "cmatrix = metrics.confusion_matrix(true_classes, predicted_class_indices)\n",
    "print(cmatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
