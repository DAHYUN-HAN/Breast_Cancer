{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import sys\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageMath\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from img_processing_256 import mask_img, rename\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotate_image_train(img):\n",
    "    rotations = np.random.randint(low=-3, high=3)\n",
    "    return np.rot90(img, rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_img_train(img):\n",
    "    fliplr = np.random.binomial(1,0.5)\n",
    "    flipud = np.random.binomial(1,0.5)\n",
    "    \n",
    "    if fliplr:\n",
    "        img = np.flip(img, 1)\n",
    "    if flipud:\n",
    "        img = np.flip(img, 0)\n",
    "        \n",
    "    return random_rotate_image_train(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    slice_size=512\n",
    "    tile_size=256\n",
    "    img_h = img.shape[0]\n",
    "    img_w = img.shape[1]\n",
    "    \n",
    "    # make sure the image is big enough to use\n",
    "    if (img_h < slice_size) or (img_w < slice_size):\n",
    "        print(\"Error - image is wrong size!\", img.shape)\n",
    "        return np.array([0])\n",
    "    \n",
    "    # pick a random place to start the crop so that the crop will be the right size\n",
    "    start_row = np.random.randint(low=0, high=(img_h - slice_size))\n",
    "    start_col = np.random.randint(low=0, high=(img_w - slice_size))\n",
    "    \n",
    "    end_row = start_row + slice_size\n",
    "    end_col = start_col + slice_size\n",
    "    \n",
    "    # crop the image and randomly rotate it\n",
    "    cropped_img = random_flip_img_train(img[start_row:end_row, start_col:end_col])\n",
    "    \n",
    "    # make sure the image is the right size\n",
    "    if cropped_img.shape[0] == cropped_img.shape[1]:\n",
    "        # resize it and return it\n",
    "        cropped_img = cropped_img.astype('float32')\n",
    "        cropped_img = cv2.resize(cropped_img, dsize=(tile_size, tile_size), interpolation=cv2.INTER_CUBIC)\n",
    "        cropped_img = np.stack((cropped_img,)*3, -1)\n",
    "        return cropped_img.reshape((tile_size, tile_size, 3))\n",
    "    \n",
    "    # else repeat until the image is the right size\n",
    "    else:\n",
    "        return crop_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(mask_dir, img_dir, Lbls, size=256, debug=True):\n",
    "    patch_list = []\n",
    "    Lbl_list = []\n",
    "    FN_list = []\n",
    "    roi_sizes = []\n",
    "    full_size = 512\n",
    "    masks = os.listdir(mask_dir)\n",
    "    counter = 0\n",
    "    if debug is None:\n",
    "        progress(counter, len(masks), 'WORKING')\n",
    "    for mask in tqdm(masks):\n",
    "        counter += 1\n",
    "        if debug is None:\n",
    "            progress(counter, len(masks), mask)    \n",
    "            \n",
    "        base_img_file = mask[:-6] + \".png\"\n",
    "        full_img = PIL.Image.open(img_dir+\"/\"+base_img_file)\n",
    "        compare = base_img_file[14:]\n",
    "        \n",
    "        try:\n",
    "            Lbl = Lbls.loc[compare]['Class']\n",
    "        except:\n",
    "            print(\"Error LabelNotFound\", base_img_file)\n",
    "            continue\n",
    "        \n",
    "        full_img_arr = np.array(full_img)[:,:]\n",
    "        ctr_row, ctr_col, too_big, full_img_arr, mask_size = mask_img(mask_dir + \"/\" + mask,full_img_arr, half=False,\n",
    "                                                                         output=debug)\n",
    "        img_h, img_w = full_img_arr.shape\n",
    "        try:\n",
    "            mask_H = mask_size[0]\n",
    "            mask_W = mask_size[1]\n",
    "            roi_size = np.max([mask_H, mask_W])\n",
    "            if debug:\n",
    "                print(\"Mask\", mask, \" Height:\", mask_H, \"Width:\", mask_W)\n",
    "        except:\n",
    "            print(\"Mask Size Error:\", mask_size, \"for\", mask)\n",
    "        # Record roi size for DDSM image crop\n",
    "        roi_sizes.append(roi_size)\n",
    "        if (ctr_row == 0) and (ctr_col == 0):\n",
    "            print(\"Error, skipping\", mask)\n",
    "            continue\n",
    "        \"\"\"\n",
    "        Extract the ROI depending on it's size\n",
    "        If the ROI is smaller than a slice extract it with some padding\n",
    "        \"\"\"\n",
    "        if roi_size < full_size:\n",
    "            if debug:\n",
    "                print(\"ROI small\", mask)\n",
    "            ## Make sure the size of the ROI is at least as big as a tile will be\n",
    "            adj_mask_H = int(np.max([full_size * 1.4, mask_H]))\n",
    "            adj_mask_W = int(np.max([full_size * 1.4, mask_W]))\n",
    "            ## Extract the full ROI with 20% padding on either side\n",
    "            start_row = int(np.max([ctr_row - (adj_mask_H // 2), 0]))\n",
    "            end_row = start_row + adj_mask_H\n",
    "            if end_row > img_h:\n",
    "                end_row = img_h\n",
    "                start_row = img_h - adj_mask_H\n",
    "            start_col = int(np.max([ctr_col - (adj_mask_W // 2), 0]))\n",
    "            end_col = start_col + adj_mask_W\n",
    "            if end_col > img_w:\n",
    "                end_col = img_w\n",
    "                start_col = img_w - adj_mask_W\n",
    "\n",
    "            # extract the ROI and randomly flip it\n",
    "            roi_img = random_flip_img_train(full_img_arr[start_row:end_row, start_col:end_col])\n",
    "        # else extract the ROI with less padding\n",
    "        else:\n",
    "            if debug:\n",
    "                print(\"ROI Big\", mask)\n",
    "            # padding for the random cropping\n",
    "            adj_mask_H = int(np.max([full_size * 1.15, mask_H]))\n",
    "            adj_mask_W = int(np.max([full_size * 1.15, mask_W]))\n",
    "            start_row = np.max([ctr_row - (adj_mask_H // 2), 0])\n",
    "            end_row = start_row + adj_mask_H\n",
    "            if end_row > img_h:\n",
    "                end_row = img_h\n",
    "                start_row = img_h - adj_mask_H\n",
    "            start_col = np.max([ctr_col - (adj_mask_W // 2), 0])\n",
    "            end_col = start_col + adj_mask_W\n",
    "            if end_col > img_w:\n",
    "                end_col = img_w\n",
    "                start_col = img_w - adj_mask_W\n",
    "            # extract the ROI and randomly flip it\n",
    "            roi_img = random_flip_img_train(full_img_arr[start_row:end_row, start_col:end_col])\n",
    "              \n",
    "        patch_1 = crop_img(roi_img)\n",
    "        patch_2 = crop_img(roi_img)\n",
    "        patch_3 = crop_img(roi_img)\n",
    "         \n",
    "        if (patch_1.shape[0] == size) and (patch_1.shape[1] == size):\n",
    "            patch_list.append(patch_1)\n",
    "            Lbl_list.append(Lbl)\n",
    "            FN_list.append(base_img_file)\n",
    "                \n",
    "        if (patch_2.shape[0] == size) and (patch_2.shape[1] == size):\n",
    "            patch_list.append(patch_2)\n",
    "            Lbl_list.append(Lbl)\n",
    "            FN_list.append(base_img_file)\n",
    "        \n",
    "        if (patch_3.shape[0] == size) and (patch_2.shape[1] == size):\n",
    "            patch_list.append(patch_3)\n",
    "            Lbl_list.append(Lbl)\n",
    "            FN_list.append(base_img_file)\n",
    "                \n",
    "    return np.array(patch_list), np.array(Lbl_list), np.array(FN_list), roi_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_pickle(\"label old ver/train_label.pkl\")\n",
    "train_labels['IMAGE_NAME2'] = train_labels.index\n",
    "train_labels = train_labels.drop_duplicates(['IMAGE_NAME2'])\n",
    "## use a copy on the local drive to make testing faster\n",
    "mask_dir = \"D:/mammography/mask/train_png/Calc\"\n",
    "img_dir = \"D:/mammography/full/train_png/Calc\"\n",
    "\n",
    "train_calc_patch, train_calc_Lbl, train_calc_FN, train_calc_roi_size = \\\n",
    "        create_patches(mask_dir, img_dir, Lbls=train_labels, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train calc patches shape:\", train_calc_patch.shape)\n",
    "print(\"Train calc Labels:\", len(train_calc_Lbl))\n",
    "print(\"Train calc File Name:\", len(train_calc_FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random images \n",
    "N = 20\n",
    "idx = random.sample(range(len(train_calc_patch)), k=N)\n",
    "plt.figure(figsize=(12,12))\n",
    "for i, j in enumerate(idx):\n",
    "    plt.subplot(5,4,i+1)\n",
    "    plt.imshow(train_calc_patch[j])\n",
    "    plt.title(train_calc_FN[j] + \" - \" + str(j)+ \"\\n\" + \"Mean:\" + str(round(np.mean(train_calc_patch[j]),3)) + \" | Var:\" + str(round(np.var(train_calc_patch[j]),3)))\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROI Mean Size:\", np.round(np.mean(train_calc_roi_size),2))\n",
    "print(\"ROI Min Size:\", np.min(train_calc_roi_size))\n",
    "print(\"ROI Max Size:\", np.max(train_calc_roi_size))\n",
    "print(\"ROI Size Std:\", np.round(np.std(train_calc_roi_size),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"Processed_abnorm_256\", \"train_calc_patch.npy\"), train_calc_patch)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"train_calc_Lbl.npy\"), np.array(train_calc_Lbl))\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"train_calc_FN.npy\"), train_calc_FN)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"train_calc_roi_size.npy\"), np.array(train_calc_roi_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.read_pickle(\"label old ver/test_label.pkl\")\n",
    "test_labels['IMAGE_NAME2'] = test_labels.index\n",
    "#test_labels = test_labels.drop_duplicates(['IMAGE_NAME2'])\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mass_training\n",
    "train_labels = pd.read_pickle(\"label old ver/train_label.pkl\")\n",
    "train_labels['IMAGE_NAME2'] = train_labels.index\n",
    "train_labels = train_labels.drop_duplicates(['IMAGE_NAME2'])\n",
    "\n",
    "## use a copy on the local drive to make testing faster\n",
    "mask_dir = \"D:/mammography/mask/train_png/Mass\"\n",
    "img_dir = \"D:/mammography/full/train_png/Mass\"\n",
    "\n",
    "train_mass_patch, train_mass_Lbl, train_mass_FN, train_mass_roi_size = \\\n",
    "    create_patches(mask_dir, img_dir, Lbls=train_labels, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random images \n",
    "N = 20\n",
    "idx = random.sample(range(len(train_mass_patch)), k=N)\n",
    "plt.figure(figsize=(12,12))\n",
    "for i, j in enumerate(idx):\n",
    "    plt.subplot(5,4,i+1)\n",
    "    plt.imshow(train_mass_patch[j].reshape(256, 256), cmap='gist_heat')\n",
    "    plt.title(train_mass_FN[j] + \" - \" + str(j)+ \"\\n\" + \"Mean:\" + str(round(np.mean(train_mass_patch[j]),3)) + \" | Var:\" + str(round(np.var(train_mass_patch[j]),3)))\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROI Mean Size:\", np.mean(train_mass_roi_size))\n",
    "print(\"ROI Min Size:\", np.min(train_mass_roi_size))\n",
    "print(\"ROI Max Size:\", np.max(train_mass_roi_size))\n",
    "print(\"ROI Size Std:\", np.std(train_mass_roi_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"Processed_abnorm_256\", \"train_mass_patch.npy\"), train_mass_patch)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"train_mass_Lbl.npy\"), np.array(train_mass_Lbl))\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"train_mass_FN.npy\"), train_mass_FN)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"train_mass_roi_size.npy\"), np.array(train_mass_roi_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(mask_dir, img_dir, Lbls, size=256, debug=True):\n",
    "    patch_list = []\n",
    "    Lbl_list = []\n",
    "    FN_list = []\n",
    "    roi_sizes = []\n",
    "    full_size = 512\n",
    "    masks = os.listdir(mask_dir)\n",
    "    counter = 0\n",
    "    if debug is None:\n",
    "        progress(counter, len(masks), 'WORKING')\n",
    "    for mask in tqdm(masks):\n",
    "        counter += 1\n",
    "        if debug is None:\n",
    "            progress(counter, len(masks), mask)    \n",
    "            \n",
    "        base_img_file = mask[:-6] + \".png\"\n",
    "        full_img = cv2.imread(img_dir+\"/\"+base_img_file, cv2.IMREAD_COLOR)\n",
    "        compare = base_img_file[10:]\n",
    "        \n",
    "        try:\n",
    "            Lbl = Lbls.loc[compare]['Class']\n",
    "        except:\n",
    "            print(\"Error LabelNotFound\", base_img_file)\n",
    "            continue\n",
    "        \n",
    "        full_img_arr = np.array(full_img)[:,:]\n",
    "        ctr_row, ctr_col, too_big, full_img_arr, mask_size = mask_img(mask_dir + \"/\" + mask,full_img_arr, half=False,\n",
    "                                                                         output=debug)\n",
    "        img_h, img_w = full_img_arr.shape\n",
    "        try:\n",
    "            mask_H = mask_size[0]\n",
    "            mask_W = mask_size[1]\n",
    "            roi_size = np.max([mask_H, mask_W])\n",
    "            if debug:\n",
    "                print(\"Mask\", mask, \" Height:\", mask_H, \"Width:\", mask_W)\n",
    "        except:\n",
    "            print(\"Mask Size Error:\", mask_size, \"for\", mask)\n",
    "        # Record roi size for DDSM image crop\n",
    "        roi_sizes.append(roi_size)\n",
    "        if (ctr_row == 0) and (ctr_col == 0):\n",
    "            print(\"Error, skipping\", mask)\n",
    "            continue\n",
    "        \"\"\"\n",
    "        Extract the ROI depending on it's size\n",
    "        If the ROI is smaller than a slice extract it with some padding\n",
    "        \"\"\"\n",
    "        if roi_size < full_size:\n",
    "            if debug:\n",
    "                print(\"ROI small\", mask)\n",
    "            ## Make sure the size of the ROI is at least as big as a tile will be\n",
    "            adj_mask_H = int(np.max([full_size * 1.4, mask_H]))\n",
    "            adj_mask_W = int(np.max([full_size * 1.4, mask_W]))\n",
    "            ## Extract the full ROI with 20% padding on either side\n",
    "            start_row = int(np.max([ctr_row - (adj_mask_H // 2), 0]))\n",
    "            end_row = start_row + adj_mask_H\n",
    "            if end_row > img_h:\n",
    "                end_row = img_h\n",
    "                start_row = img_h - adj_mask_H\n",
    "            start_col = int(np.max([ctr_col - (adj_mask_W // 2), 0]))\n",
    "            end_col = start_col + adj_mask_W\n",
    "            if end_col > img_w:\n",
    "                end_col = img_w\n",
    "                start_col = img_w - adj_mask_W\n",
    "\n",
    "            # extract the ROI and randomly flip it\n",
    "            roi_img = random_flip_img_train(full_img_arr[start_row:end_row, start_col:end_col])\n",
    "        # else extract the ROI with less padding\n",
    "        else:\n",
    "            if debug:\n",
    "                print(\"ROI Big\", mask)\n",
    "            # padding for the random cropping\n",
    "            adj_mask_H = int(np.max([full_size * 1.15, mask_H]))\n",
    "            adj_mask_W = int(np.max([full_size * 1.15, mask_W]))\n",
    "            start_row = np.max([ctr_row - (adj_mask_H // 2), 0])\n",
    "            end_row = start_row + adj_mask_H\n",
    "            if end_row > img_h:\n",
    "                end_row = img_h\n",
    "                start_row = img_h - adj_mask_H\n",
    "            start_col = np.max([ctr_col - (adj_mask_W // 2), 0])\n",
    "            end_col = start_col + adj_mask_W\n",
    "            if end_col > img_w:\n",
    "                end_col = img_w\n",
    "                start_col = img_w - adj_mask_W\n",
    "            # extract the ROI and randomly flip it\n",
    "            roi_img = random_flip_img_train(full_img_arr[start_row:end_row, start_col:end_col])\n",
    "              \n",
    "        patch_1 = crop_img(roi_img)\n",
    "        patch_2 = crop_img(roi_img)\n",
    "        patch_3 = crop_img(roi_img)\n",
    "         \n",
    "        if (patch_1.shape[0] == size) and (patch_1.shape[1] == size):\n",
    "            patch_list.append(patch_1)\n",
    "            Lbl_list.append(Lbl)\n",
    "            FN_list.append(base_img_file)\n",
    "                \n",
    "        if (patch_2.shape[0] == size) and (patch_2.shape[1] == size):\n",
    "            patch_list.append(patch_2)\n",
    "            Lbl_list.append(Lbl)\n",
    "            FN_list.append(base_img_file)\n",
    "        \n",
    "        if (patch_3.shape[0] == size) and (patch_2.shape[1] == size):\n",
    "            patch_list.append(patch_3)\n",
    "            Lbl_list.append(Lbl)\n",
    "            FN_list.append(base_img_file)\n",
    "                \n",
    "    return np.array(patch_list), np.array(Lbl_list), np.array(FN_list), roi_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/326 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mishaped mask, resizing mask D:/mammography/mask/test_png/Calc/Calc-Test_P_00038_LEFT_CC_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument 1 must be sequence of length 2, not 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2fc45978e1ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtest_calc_patch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_calc_Lbl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_calc_FN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_calc_roi_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcreate_patches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLbls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-fad6fd129c65>\u001b[0m in \u001b[0;36mcreate_patches\u001b[1;34m(mask_dir, img_dir, Lbls, size, debug)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mfull_img_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         ctr_row, ctr_col, too_big, full_img_arr, mask_size = mask_img(mask_dir + \"/\" + mask,full_img_arr, half=False,\n\u001b[1;32m---> 28\u001b[1;33m                                                                          output=debug)\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mimg_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_img_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\mammo\\Breast_Cancer\\img_processing_256.py\u001b[0m in \u001b[0;36mmask_img\u001b[1;34m(mask_path, full_image_arr, slice_size, return_size, half, output)\u001b[0m\n\u001b[0;32m     69\u001b[0m                         \u001b[1;31m# reshape the mask to match the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                         \u001b[1;31m#mask_arr = imresize(mask_arr, full_image_arr.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                         \u001b[0mmask_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_image_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mammo\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   1903\u001b[0m                 )\n\u001b[0;32m   1904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1905\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1907\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument 1 must be sequence of length 2, not 3"
     ]
    }
   ],
   "source": [
    "#Calc_test\n",
    "test_labels = pd.read_pickle(\"label old ver/test_label.pkl\")\n",
    "test_labels['IMAGE_NAME2'] = test_labels.index\n",
    "test_labels = test_labels.drop_duplicates(['IMAGE_NAME2'])\n",
    "\n",
    "## use a copy on the local drive to make testing faster\n",
    "mask_dir = \"D:/mammography/mask/test_png/Calc\"\n",
    "img_dir = \"D:/mammography/full/test_png/Calc\"\n",
    "\n",
    "test_calc_patch, test_calc_Lbl, test_calc_FN, test_calc_roi_size = \\\n",
    "    create_patches(mask_dir, img_dir, Lbls=test_labels, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test calc patches shape:\", test_calc_patch.shape)\n",
    "print(\"Test calc Labels:\", len(test_calc_Lbl))\n",
    "print(\"Test calc File Name:\", len(test_calc_FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random images \n",
    "N = 20\n",
    "idx = random.sample(range(len(test_calc_patch)), k=N)\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, j in enumerate(idx):\n",
    "    plt.subplot(10,2,i+1)\n",
    "    plt.imshow(test_calc_patch[j].reshape(256, 256), cmap='gist_heat')\n",
    "    plt.title(test_calc_FN[j] + \" - \" + str(j)+ \"\\n\" + \"Mean:\" + str(round(np.mean(test_calc_patch[j]),3)) + \" | Var:\" + str(round(np.var(test_calc_patch[j]),3)))\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROI Mean Size:\", np.round(np.mean(test_calc_roi_size),2))\n",
    "print(\"ROI Min Size:\", np.min(test_calc_roi_size))\n",
    "print(\"ROI Max Size:\", np.max(test_calc_roi_size))\n",
    "print(\"ROI Size Std:\", np.round(np.std(test_calc_roi_size),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"Processed_abnorm_256\", \"test_calc_patch.npy\"), test_calc_patch)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"test_calc_Lbl.npy\"), np.array(test_calc_Lbl))\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"test_calc_FN.npy\"), test_calc_FN)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"test_calc_roi_size.npy\"), np.array(test_calc_roi_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mass_test\n",
    "test_labels = pd.read_pickle(\"label old ver/test_label.pkl\")\n",
    "test_labels['IMAGE_NAME2'] = test_labels.index\n",
    "test_labels = test_labels.drop_duplicates(['IMAGE_NAME2'])\n",
    "\n",
    "## use a copy on the local drive to make testing faster\n",
    "mask_dir = \"D:/mammography/mask/test_png/Mass\"\n",
    "img_dir = \"D:/mammography/full/test_png/Mass\"\n",
    "\n",
    "test_mass_patch, test_mass_Lbl, test_mass_FN, test_mass_roi_size = \\\n",
    "    create_patches(mask_dir, img_dir, Lbls=test_labels, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test mass patches shape:\", test_mass_patch.shape)\n",
    "print(\"test mass Labels:\", len(test_mass_Lbl))\n",
    "print(\"test mass File Name:\", len(test_mass_FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random images \n",
    "N = 16\n",
    "idx = random.sample(range(len(test_mass_patch)), k=N)\n",
    "plt.figure(figsize=(12,12))\n",
    "for i, j in enumerate(idx):\n",
    "    plt.subplot(5,4,i+1)\n",
    "    plt.imshow(test_mass_patch[j].reshape(256, 256), cmap='gray')\n",
    "    plt.title(test_mass_FN[j] + \" - \" + str(j)) #+ \"\\n\" + \"Mean:\" + str(round(np.mean(test_mass_patch[j]),3)) + \" | Var:\" + str(round(np.var(test_mass_patch[j]),3)))\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROI Mean Size:\", np.round(np.mean(test_mass_roi_size),2))\n",
    "print(\"ROI Min Size:\", np.min(test_mass_roi_size))\n",
    "print(\"ROI Max Size:\", np.max(test_mass_roi_size))\n",
    "print(\"ROI Size Std:\", np.round(np.std(test_mass_roi_size),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"Processed_abnorm_256\", \"test_mass_patch.npy\"), test_mass_patch)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"test_mass_Lbl.npy\"), np.array(test_mass_Lbl))\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"test_mass_FN.npy\"), test_mass_FN)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"test_mass_roi_size.npy\"), np.array(test_mass_roi_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patch = np.concatenate([train_mass_patch, train_calc_patch], axis=0)\n",
    "train_Lbl = np.concatenate([train_mass_Lbl, train_calc_Lbl], axis=0)\n",
    "train_FN = np.concatenate([train_mass_FN, train_calc_FN], axis=0)\n",
    "\n",
    "test_patch = np.concatenate([test_mass_patch, test_calc_patch], axis=0)\n",
    "test_Lbl = np.concatenate([test_mass_Lbl, test_calc_Lbl], axis=0)\n",
    "test_FN = np.concatenate([test_mass_FN, test_calc_FN], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Patches:\", train_patch.shape)\n",
    "print(\"Train Lables:\", train_Lbl.shape)\n",
    "print(\"Train File Names:\", train_FN.shape)\n",
    "\n",
    "print(\"Test Patches:\", test_patch.shape)\n",
    "print(\"Test Lables:\", test_Lbl.shape)\n",
    "print(\"Test File Names:\", test_FN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"Processed_abnorm_256\", \"abnormal_train_patch.npy\"), train_patch)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"abnormal_train_Lbl.npy\"), train_Lbl)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"abnormal_train_FN.npy\"), train_FN)\n",
    "\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"abnormal_test_patch.npy\"), test_patch)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"abnormal_test_Lbl.npy\"), test_Lbl)\n",
    "np.save(os.path.join(\"Processed_abnorm_256\", \"abnormal_test_FN.npy\"), test_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "CBIS_train_patches = np.load(os.path.join(\"./Processed_abnorm_256\", \"abnormal_train_patch.npy\" ))\n",
    "CBIS_train_labels = np.load(os.path.join(\"./Processed_abnorm_256\", \"abnormal_train_Lbl.npy\" ))\n",
    "CBIS_train_FNs = np.load(os.path.join(\"./Processed_abnorm_256\", \"abnormal_train_FN.npy\" ))\n",
    "\n",
    "#test data\n",
    "CBIS_test_patches = np.load(os.path.join(\"./Processed_abnorm_256\", \"abnormal_test_patch.npy\" ))\n",
    "CBIS_test_labels = np.load(os.path.join(\"./Processed_abnorm_256\", \"abnormal_test_Lbl.npy\" ))\n",
    "CBIS_test_FNs = np.load(os.path.join(\"./Processed_abnorm_256\", \"abnormal_test_FN.npy\" ))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Abnaormal train Patches:\", CBIS_train_patches.shape)\n",
    "print(\"Abnaormal train Labels:\", CBIS_train_labels.shape)\n",
    "print(\"Abnaormal train File Names:\", CBIS_train_FNs.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Abnaormal test Patches:\", CBIS_test_patches.shape)\n",
    "print(\"Abnaormal test Labels:\", CBIS_test_labels.shape)\n",
    "print(\"Abnaormal test File Names:\", CBIS_test_FNs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CBIS_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MALIGNANT_mass=0\n",
    "MALIGNANT_calcification=0\n",
    "BENIGN_calcification = 0\n",
    "BENIGN_mass = 0\n",
    "\n",
    "for name in CBIS_test_labels:\n",
    "    if(name == 'MALIGNANT_mass'):\n",
    "        MALIGNANT_mass += 1\n",
    "    elif(name == 'MALIGNANT_calcification'):\n",
    "        MALIGNANT_calcification += 1\n",
    "    elif(name == 'BENIGN_calcification'):\n",
    "        BENIGN_calcification += 1\n",
    "    elif(name == 'BENIGN_mass'):\n",
    "        BENIGN_mass += 1\n",
    "print(MALIGNANT_mass)\n",
    "print(MALIGNANT_calcification)\n",
    "print(BENIGN_calcification)\n",
    "print(BENIGN_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "idx = random.sample(range(len(CBIS_train_patches)), k=N)\n",
    "plt.figure(figsize=(15,15))\n",
    "for i, j in enumerate(idx):\n",
    "    plt.subplot(5,4,i+1)\n",
    "    plt.imshow(CBIS_train_patches[j].reshape(256, 256), cmap='gist_heat')\n",
    "    plt.title(CBIS_train_labels[j] + \"\\n\" + CBIS_train_FNs[j] + str(j))\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine train and test data \n",
    "\n",
    "CBIS_all_patches = np.concatenate([CBIS_train_patches, CBIS_test_patches], axis=0)\n",
    "CBIS_all_labels = np.concatenate([CBIS_train_labels, CBIS_test_labels], axis=0)\n",
    "CBIS_all_FNs = np.concatenate([CBIS_train_FNs, CBIS_test_FNs], axis=0)\n",
    "\n",
    "CBIS_all_patches, CBIS_all_labels, CBIS_all_FNs = \\\n",
    "shuffle(CBIS_all_patches, CBIS_all_labels, CBIS_all_FNs, random_state=19510705)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the combined data into train and test\n",
    "train_patches, test_patches, train_labels, test_labels, train_FNs, test_FNs = \\\n",
    "train_test_split(CBIS_all_patches, CBIS_all_labels, CBIS_all_FNs, test_size = 0.183565, random_state=19430727)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "train_images = train_patches\n",
    "train_labels = train_labels\n",
    "train_FNs = train_FNs\n",
    "\n",
    "#test data\n",
    "test_images =  test_patches\n",
    "test_labels = test_labels\n",
    "test_FNs = test_FNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Normal to 0 \n",
    "train_labels_en = le.transform(train_labels)\n",
    "#train_labels_en[train_labels_en==]=0\n",
    "\n",
    "test_labels_en = le.transform(test_labels)\n",
    "#test_labels_en[test_labels_en==5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bin_labels = np.zeros(len(train_labels_en)).astype(np.int32)\n",
    "train_bin_labels[train_labels_en != 0] = 1\n",
    "\n",
    "test_bin_labels = np.zeros(len(test_labels_en)).astype(np.int32)\n",
    "test_bin_labels[test_labels_en != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"Label\", \"train_labels_en.npy\"), train_labels_en)\n",
    "np.save(os.path.join(\"Label\", \"test_labels_en.npy\"), test_labels_en)\n",
    "np.save(os.path.join(\"Label\", \"train_bin_labels.npy\"), train_bin_labels)\n",
    "np.save(os.path.join(\"Label\", \"test_bin_labels.npy\"), test_bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test, y_val_multi, y_test_multi = \\\n",
    "    train_test_split(test_images, test_bin_labels, test_labels_en, test_size=0.5, random_state=19730104)\n",
    "X_train, y_train, y_train_multi = \\\n",
    "     shuffle(train_images, train_bin_labels, train_labels_en, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_images\n",
    "y_test = test_labels_en\n",
    "\n",
    "X_train = train_images\n",
    "y_train = train_labels_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"Data/256\", 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(\"Data/256\", 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(\"Data/256\", 'train_labels_multi.npy'), y_train_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"Data/256\", 'X_val.npy'), X_val)\n",
    "np.save(os.path.join(\"Data/256\", 'y_val.npy'), y_val)\n",
    "np.save(os.path.join(\"Data/256\", 'y_val_labels_multi.npy'), y_val_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"Data/256\", 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(\"Data/256\", 'y_test.npy'), y_test)\n",
    "np.save(os.path.join(\"Data/256\", 'y_test_labels_multi.npy'), y_test_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
