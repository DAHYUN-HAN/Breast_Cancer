{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adadelta, Adagrad, Adamax, Nadam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization, GlobalAveragePooling2D  \n",
    "from tensorflow.keras.backend import batch_normalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from packaging import version\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training():\n",
    "    \"\"\"\n",
    "    Load the training set (excluding baseline patches)\n",
    "    \"\"\"\n",
    "    images = np.load(os.path.join('Data_new3', 'X_train.npy'))\n",
    "    labels = np.load(os.path.join('Data_new3', 'train_labels_multi.npy'))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_testing():\n",
    "    \"\"\"\n",
    "    Load the test set (abnormalities patches and labels, no baseline)\n",
    "    \"\"\"\n",
    "    images = np.load(os.path.join('Data_new3', 'X_test.npy'))\n",
    "    labels = np.load(os.path.join('Data_new3', 'y_test_labels_multi.npy'))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def remap_label(l):\n",
    "    \"\"\"\n",
    "    Remap the labels to:\n",
    "        0 -> mass benign \n",
    "        1 -> mass malignant\n",
    "        2 -> calcification benign\n",
    "        3 -> calcification malignant\n",
    "    \"\"\"\n",
    "    if 1 <= l <= 4:\n",
    "        return l-1\n",
    "    else:\n",
    "        print(\"[WARN] Unrecognized label (%d)\" % l)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2913 \t Test size: 655\n",
      "Image size: 256x256\n"
     ]
    }
   ],
   "source": [
    "# Load training and test images (abnormalities only, no baseline)\n",
    "train_images, train_labels= load_training()\n",
    "test_images, test_labels= load_testing()\n",
    "\n",
    "# Number of images\n",
    "n_train_img = train_images.shape[0]\n",
    "n_test_img = test_images.shape[0]\n",
    "print(\"Train size: %d \\t Test size: %d\" % (n_train_img, n_test_img))\n",
    "\n",
    "# Compute width and height of images\n",
    "img_w = train_images.shape[1]\n",
    "img_h = train_images.shape[2]\n",
    "print(\"Image size: %dx%d\" % (img_w, img_h))\n",
    "\n",
    "# Convert the labels to categorical format\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels_raw = test_labels.copy()\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Create a new dimension for color in the images arrays\n",
    "train_images = train_images.reshape((n_train_img, img_w, img_h, 1))\n",
    "test_images = test_images.reshape((n_test_img, img_w, img_h, 1))\n",
    "\n",
    "# Convert from 16-bit (0-65535) to to 8-bit (0-255)\n",
    "train_images = train_images.astype('uint16') / 255\n",
    "test_images = test_images.astype('uint16') / 255\n",
    "\n",
    "# Replicate the only color channel (gray) 3 times, for VGGNet compatibility\n",
    "train_images = np.repeat(train_images, 3, axis=3)\n",
    "test_images = np.repeat(test_images, 3, axis=3)\n",
    "\n",
    "# Shuffle the training set (originally sorted by label)\n",
    "perm = np.random.permutation(n_train_img)\n",
    "train_images = train_images[perm]\n",
    "train_labels = train_labels[perm]\n",
    "\n",
    "# Create a generator for training images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=180,\n",
    "    shear_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# Fit the generator with some images\n",
    "train_datagen.fit(train_images)\n",
    "\n",
    "# Split train images into actual training and validation\n",
    "train_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='training')\n",
    "validation_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='validation')\n",
    "\n",
    "# Preprocess the test images as well\n",
    "preprocess_input(test_images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using VGG16 convolutional base and new FC final layer\n",
    "\n",
    "def create_vgg16(verbose=False, fc_size=256, dropout=None):\n",
    "\n",
    "    vgg16_base = VGG16(weights='imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(256, 256, 3))\n",
    "    vgg16 = models.Sequential()\n",
    "    vgg16.add(vgg16_base)\n",
    "\n",
    "    vgg16.add(layers.Flatten())\n",
    "    if dropout is not None:\n",
    "        vgg16.add(layers.Dropout(dropout))\n",
    "    vgg16.add(layers.Dense(fc_size, activation='relu'))\n",
    "    vgg16.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "    # Freeze the convolutional base\n",
    "    vgg16_base.trainable = False\n",
    "    \n",
    "    if verbose:\n",
    "        vgg16_base.summary()\n",
    "        vgg16.summary()\n",
    "\n",
    "    return vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a VGG16 network with custom final layer\n",
    "vgg16_fe_drop_128 = create_vgg16(dropout=0.5, fc_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_fe_drop_128.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
